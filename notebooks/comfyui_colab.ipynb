{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArtHommage/HommageTools/blob/main/notebooks/comfyui_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Upgrade Core Tools (Run this cell first)\n",
        "# -------------------------------------------------\n",
        "print(\"Upgrading pip...\")\n",
        "!pip install --upgrade pip\n",
        "\n",
        "print(\"\\nUpgrading setuptools...\")\n",
        "!pip install --upgrade setuptools\n",
        "\n",
        "print(\"\\n---------------------------------------------------------------------\")\n",
        "print(\"IMPORTANT: Core tools upgraded.\")\n",
        "print(\"Please RESTART THE RUNTIME now using the menu options before proceeding.\")\n",
        "print(\"(e.g., Runtime -> Restart runtime in Google Colab)\")\n",
        "print(\"---------------------------------------------------------------------\")"
      ],
      "metadata": {
        "id": "XfN5SHhrNFs1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "outputId": "d98d1786-4954-44f2-b4d5-4f70b4fbf107"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upgrading pip...\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.0.1\n",
            "\n",
            "Upgrading setuptools...\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-79.0.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Downloading setuptools-79.0.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: setuptools\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed setuptools-79.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "6078116fb3f648a09cedee4d79739369"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------------------------------------------------------------\n",
            "IMPORTANT: Core tools upgraded.\n",
            "Please RESTART THE RUNTIME now using the menu options before proceeding.\n",
            "(e.g., Runtime -> Restart runtime in Google Colab)\n",
            "---------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Install Dependencies (Run this cell AFTER restarting the runtime)\n",
        "# -----------------------------------------------------------------------\n",
        "print(\"Installing jedi (for ipython)...\")\n",
        "!pip install \"jedi>=0.16\"\n",
        "\n",
        "print(\"\\nInstalling specific NumPy version required by dependencies...\")\n",
        "# This version range should satisfy thinc, tensorflow, numba, ultralytics etc.\n",
        "!pip install \"numpy>=2.0.0,<2.1.0\"\n",
        "\n",
        "print(\"\\nInstalling main project packages...\")\n",
        "# List all your main packages here. Combining them helps pip resolve dependencies.\n",
        "# Adding piexif and albumentations based on your previous install list.\n",
        "!pip install \\\n",
        "    transparent_background \\\n",
        "    piexif \\\n",
        "    ultralytics \\\n",
        "    surrealist \\\n",
        "    blend_modes \\\n",
        "    gguf \\\n",
        "    dynamicprompts \\\n",
        "    pygtrans \\\n",
        "    segment_anything \\\n",
        "    dill \\\n",
        "    boto3 \\\n",
        "    fake_useragent \\\n",
        "    redis \\\n",
        "    fal_client \\\n",
        "    replicate \\\n",
        "    psd-tools \\\n",
        "    onnxruntime \\\n",
        "    oidn \\\n",
        "    color-matcher \\\n",
        "    albumentations \\\n",
        "    omegaconf \\\n",
        "    pytorch_lightning \\\n",
        "    open_clip_torch \\\n",
        "    xformers \\\n",
        "    transformers==4.49.0 \\\n",
        "    accelerate>=1.6.0 \\\n",
        "    diffusers>=0.33.1 \\\n",
        "    transformers>=4.46.2 \\\n",
        "    scipy>=1.12.0 \\\n",
        "    torchsde>=0.2.6 \\\n",
        "    einops \\\n",
        "    safetensors\n",
        "\n",
        "print(\"\\n---------------------------------------------------------------------\")\n",
        "print(\"Dependencies installation attempted.\")\n",
        "print(\"Check output above for any errors or new dependency conflicts.\")\n",
        "print(\"---------------------------------------------------------------------\")\n",
        "\n",
        "print(\"\\nVerifying installed NumPy version...\")\n",
        "!pip show numpy"
      ],
      "metadata": {
        "id": "Rasr-nUK_RW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transparent_background piexif ultralytics surrealist blend_modes gguf dynamicprompts pygtrans segment_anything dill boto3 fake_useragent redis fal_client replicate psd-tools onnxruntime oidn color-matcher albumentations --upgrade\n",
        "#!pip install omegaconf pytorch_lightning open_clip_torch\n",
        "#!pip uninstall xformers -y\n",
        "#!pip install xformers\n",
        "#!pip install --upgrade transformers==4.49.0\n",
        "#!pip install \"numpy>=2.0.0,<2.1.0\" # Experimental"
      ],
      "metadata": {
        "id": "BoNqwrsF5xUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bbbbbbbbbb",
        "outputId": "32607a1e-3e4c-4bd1-debe-cc59d529d56e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "/\n",
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/MyDrive/ComfyUI\n",
            "-= Install dependencies =-\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121, https://download.pytorch.org/whl/cu118, https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: xformers!=0.0.18 in /usr/local/lib/python3.11/dist-packages (0.0.29.post3)\n",
            "Collecting comfyui-frontend-package==1.16.9 (from -r requirements.txt (line 1))\n",
            "  Downloading comfyui_frontend_package-1.16.9-py3-none-any.whl.metadata (117 bytes)\n",
            "Collecting comfyui-workflow-templates==0.1.3 (from -r requirements.txt (line 2))\n",
            "  Downloading comfyui_workflow_templates-0.1.3-py3-none-any.whl.metadata (55 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.6.0+cu124)\n",
            "Collecting torchsde (from -r requirements.txt (line 4))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (4.49.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.21.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.2.0)\n",
            "Requirement already satisfied: safetensors>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.5.3)\n",
            "Requirement already satisfied: aiohttp>=3.11.8 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (3.11.15)\n",
            "Requirement already satisfied: yarl>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (1.19.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (6.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (5.9.5)\n",
            "Requirement already satisfied: kornia>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (0.8.0)\n",
            "Collecting spandrel (from -r requirements.txt (line 23))\n",
            "  Downloading spandrel-0.4.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (0.13.1)\n",
            "Collecting av (from -r requirements.txt (line 25))\n",
            "  Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 3)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 3)) (1.3.0)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 4))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 9)) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 9)) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 9)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.28.1->-r requirements.txt (line 9)) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 13)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 13)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 13)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 13)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 13)) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.8->-r requirements.txt (line 13)) (0.3.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl>=1.18.0->-r requirements.txt (line 14)) (3.10)\n",
            "Requirement already satisfied: kornia_rs>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from kornia>=0.7.1->-r requirements.txt (line 22)) (0.1.8)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile->-r requirements.txt (line 24)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 24)) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r requirements.txt (line 3)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 9)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 9)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.28.1->-r requirements.txt (line 9)) (2025.1.31)\n",
            "Downloading comfyui_frontend_package-1.16.9-py3-none-any.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m150.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comfyui_workflow_templates-0.1.3-py3-none-any.whl (32.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m32.7/32.7 MB\u001b[0m \u001b[31m175.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "Downloading spandrel-0.4.1-py3-none-any.whl (305 kB)\n",
            "Downloading av-14.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m196.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: trampoline, comfyui-workflow-templates, comfyui-frontend-package, av, torchsde, spandrel\n",
            "Successfully installed av-14.3.0 comfyui-frontend-package-1.16.9 comfyui-workflow-templates-0.1.3 spandrel-0.4.1 torchsde-0.2.6 trampoline-0.1.2\n"
          ]
        }
      ],
      "source": [
        "#@title Environment Setup\n",
        "\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = False  #@param {type:\"boolean\"}\n",
        "WORKSPACE = 'ComfyUI'\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI from main branch =-\n",
        "  !git fetch origin\n",
        "  !git checkout master\n",
        "  !git reset --hard origin/master\n",
        "  !git pull origin master\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "!pip install \"numpy>=2.0.0,<2.1.0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with cloudflared (Recommended Way)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579a8827-2245-427f-b775-877bbe9d3f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-21 01:41:39--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.4.0/cloudflared-linux-amd64.deb [following]\n",
            "--2025-04-21 01:41:39--  https://github.com/cloudflare/cloudflared/releases/download/2025.4.0/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/d7e7703c-c0be-4512-b40f-145c402e03fd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250421%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250421T014139Z&X-Amz-Expires=300&X-Amz-Signature=09f14f782eb579927660255dd1d2bfafb056f5f7d93e3a68d27eacfa0624420f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-04-21 01:41:39--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/d7e7703c-c0be-4512-b40f-145c402e03fd?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250421%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250421T014139Z&X-Amz-Expires=300&X-Amz-Signature=09f14f782eb579927660255dd1d2bfafb056f5f7d93e3a68d27eacfa0624420f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18554330 (18M) [application/octet-stream]\n",
            "Saving to: â€˜cloudflared-linux-amd64.deb.121â€™\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  17.69M  88.5MB/s    in 0.2s    \n",
            "\n",
            "2025-04-21 01:41:40 (88.5 MB/s) - â€˜cloudflared-linux-amd64.deb.121â€™ saved [18554330/18554330]\n",
            "\n",
            "Selecting previously unselected package cloudflared.\n",
            "(Reading database ... 126332 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2025.2.1) ...\n",
            "Setting up cloudflared (2025.2.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-04-21 01:42:29.427\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m[ComfyUI-Manager] 'numpy' dependency were fixed\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   1.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "   1.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "  15.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "\n",
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers attention\n",
            "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.29\n",
            "ComfyUI frontend version: 1.16.9\n",
            "[Prompt Server] web root: /usr/local/lib/python3.11/dist-packages/comfyui_frontend_package/static\n",
            "[rvtools \u001b[0;32mINFO\u001b[0m] RvTools v2 Version: 2.3.8\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "\n",
            "\u001b[92m[rgthree-comfy] Loaded 42 epic nodes. ðŸŽ‰\u001b[00m\n",
            "\n",
            "NumExpr defaulting to 8 threads.\n",
            "2025-04-21 01:48:44.634749: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745200124.654477    3949 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745200124.660401    3949 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-21 01:48:44.680301: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "install lark...\n",
            "Package lark installed successfully\n",
            "\u001b[34m[ComfyUI-Easy-Use] server: \u001b[0mv1.2.8 \u001b[92mLoaded\u001b[0m\n",
            "\u001b[34m[ComfyUI-Easy-Use] web root: \u001b[0m/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use/web_version/v2 \u001b[92mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Impact-Pack (V8.8.1)\n",
            "[Impact Pack] Wildcards loading done.\n",
            "\u001b[34mWAS Node Suite: \u001b[0mOpenCV Python FFMPEG support is enabled\u001b[0m\n",
            "\u001b[34mWAS Node Suite \u001b[93mWarning: \u001b[0m`ffmpeg_bin_path` is not set in `/content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\u001b[0m\n",
            "\u001b[34mWAS Node Suite: \u001b[0mFinished.\u001b[0m \u001b[32mLoaded\u001b[0m \u001b[0m220\u001b[0m \u001b[32mnodes successfully.\u001b[0m\n",
            "\n",
            "\t\u001b[3m\u001b[93m\"Art is the voice of the soul, expressing what words cannot.\"\u001b[0m\u001b[3m - Unknown\u001b[0m\n",
            "\n",
            "Adding /content/drive/MyDrive/ComfyUI/custom_nodes to sys.path\n",
            "Could not find efficiency nodes\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/node_wrappers/dwpose.py:26: UserWarning: DWPose: Onnxruntime not found or doesn't come with acceleration providers, switch to OpenCV with CPU device. DWPose might run very slowly\n",
            "  warnings.warn(\"DWPose: Onnxruntime not found or doesn't come with acceleration providers, switch to OpenCV with CPU device. DWPose might run very slowly\")\n",
            "Loaded ControlNetPreprocessors nodes from /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "Could not find AdvancedControlNet nodes\n",
            "Could not find AnimateDiff nodes\n",
            "Could not find IPAdapter nodes\n",
            "Could not find VideoHelperSuite nodes\n",
            "Could not load ImpactPack nodes Could not find ImpactPack nodes\n",
            "### Loading: ComfyUI-Impact-Subpack (V1.2.9)\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "[Impact Subpack] ultralytics_bbox: /content/drive/MyDrive/ComfyUI/models/ultralytics/bbox\n",
            "[Impact Subpack] ultralytics_segm: /content/drive/MyDrive/ComfyUI/models/ultralytics/segm\n",
            "------------------------------------------\n",
            "\u001b[34mComfyroll Studio v1.76 : \u001b[92m 175 Nodes Loaded\u001b[0m\n",
            "------------------------------------------\n",
            "** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md\n",
            "** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki\n",
            "------------------------------------------\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "### Loading: ComfyUI-Inspire-Pack (V1.14.1)\n",
            "Loaded Apply Style Model Adjust node - Use this for better control over style vs prompt balance\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "\u001b[92m[tinyterraNodes] \u001b[32mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Manager (V3.30.9)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "### ComfyUI Version: v0.3.29-14-g2c735c13 | Released on '2025-04-20'\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "(pysssss:WD14Tagger) [DEBUG] Available ORT providers: AzureExecutionProvider, CPUExecutionProvider\n",
            "(pysssss:WD14Tagger) [DEBUG] Using ORT providers: CUDAExecutionProvider, CPUExecutionProvider\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "FETCH ComfyRegistry Data: 5/82\n",
            "FETCH ComfyRegistry Data: 10/82\n",
            "FETCH ComfyRegistry Data: 15/82\n",
            "FETCH ComfyRegistry Data: 20/82\n",
            "FETCH ComfyRegistry Data: 25/82\n",
            "FETCH ComfyRegistry Data: 30/82\n",
            "FETCH ComfyRegistry Data: 35/82\n",
            "FETCH ComfyRegistry Data: 40/82\n",
            "FETCH ComfyRegistry Data: 45/82\n",
            "FETCH ComfyRegistry Data: 50/82\n",
            "FETCH ComfyRegistry Data: 55/82\n",
            "FETCH ComfyRegistry Data: 60/82\n",
            "Currently enabled native sdp backends: ['flash', 'math', 'mem_efficient', 'cudnn']\n",
            "Xformers is installed!\n",
            "Flash Attn is not installed!\n",
            "Sage Attn is not installed!\n",
            "FETCH ComfyRegistry Data: 65/82\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "   0.6 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   1.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Apply_Style_Model_Adjust\n",
            "   1.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-image-saver\n",
            "   1.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-randomsize\n",
            "   1.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Noise\n",
            "   1.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-plasma\n",
            "   1.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/jps-nodes\n",
            "   1.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Align\n",
            "   1.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-detail-daemon\n",
            "   1.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-florence2\n",
            "   2.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ext\n",
            "   2.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/cg-use-everywhere\n",
            "   2.7 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inpaint-cropandstitch\n",
            "   2.9 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   3.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-subpack\n",
            "   3.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/masquerade\n",
            "   4.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-wd14-tagger\n",
            "   5.8 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_tinyterraNodes\n",
            "   6.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui\n",
            "   6.6 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/execution-inversion-demo-comfyui\n",
            "   6.7 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-various\n",
            "   6.8 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_essentials\n",
            "   7.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-kjnodes\n",
            "   7.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-dynamicprompts\n",
            "   8.6 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspyrenet-rembg\n",
            "   9.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_RH_FramePack\n",
            "   9.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyMath\n",
            "  11.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_ultimatesdupscale\n",
            "  11.7 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-tensorops\n",
            "  12.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspire-pack\n",
            "  13.7 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-custom-scripts\n",
            "  14.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Chibi-Nodes\n",
            "  15.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_nyjy\n",
            "  16.7 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ppm\n",
            "  16.8 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-pack\n",
            "  21.7 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_ExtraModels\n",
            "  26.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/HommageTools\n",
            "  27.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Comfyroll_CustomNodes\n",
            "  27.9 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-supir\n",
            "  33.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "  77.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-art-venture\n",
            "  96.9 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-RvTools_v2\n",
            " 141.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_layerstyle\n",
            " 141.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            " 142.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "\n",
            "\n",
            "ComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\n",
            "\n",
            "FETCH ComfyRegistry Data: 70/82\n",
            "FETCH ComfyRegistry Data: 75/82\n",
            "This is the URL to access ComfyUI: https://thomas-sell-glory-pray.trycloudflare.com                                          |\n",
            "FETCH ComfyRegistry Data: 80/82\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/remote\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "[Inspire Pack] IPAdapterPlus is not installed.\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.0.0 - Processing\n",
            "Error generating prompt: expected string or bytes-like object, got 'SamplingResult'\n",
            "Error details: expected string or bytes-like object, got 'SamplingResult'\n",
            "Using xformers attention in VAE\n",
            "Using xformers attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "CLIP/text encoder model load device: cpu, offload device: cpu, current: cpu, dtype: torch.float16\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type FLUX\n",
            "Requested to load Flux\n",
            "loaded partially 10916.445 10916.334106445312 0\n",
            "100% 28/28 [11:29<00:00, 24.63s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1299.67 seconds\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.0.0 - Processing\n",
            "Error generating prompt: expected string or bytes-like object, got 'SamplingResult'\n",
            "Error details: expected string or bytes-like object, got 'SamplingResult'\n",
            "Requested to load Flux\n",
            "loaded partially 13157.744 13151.697387695312 0\n",
            "100% 28/28 [03:56<00:00,  8.44s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 457.671875 319.7467155456543 True\n",
            "Prompt executed in 253.70 seconds\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.0.0 - Processing\n",
            "Error generating prompt: expected string or bytes-like object, got 'SamplingResult'\n",
            "Error details: expected string or bytes-like object, got 'SamplingResult'\n",
            "Requested to load Flux\n",
            "loaded partially 12706.16 12706.045043945312 0\n",
            "100% 28/28 [05:32<00:00, 11.89s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 351.68 seconds\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.0.0 - Processing\n",
            "Error generating prompt: expected string or bytes-like object, got 'SamplingResult'\n",
            "Error details: expected string or bytes-like object, got 'SamplingResult'\n",
            "Requested to load Flux\n",
            "loaded partially 12706.16 12706.045043945312 0\n",
            "100% 28/28 [05:32<00:00, 11.89s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 363.66 seconds\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.0.0 - Processing\n",
            "got prompt\n",
            "Error generating prompt: expected string or bytes-like object, got 'SamplingResult'\n",
            "Error details: expected string or bytes-like object, got 'SamplingResult'\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 10502.0 10501.94140625 0\n",
            "  4% 1/28 [00:29<13:17, 29.54s/it]\n",
            "Restarting... [Legacy Mode]\n",
            "\n",
            "\n",
            "Command: ['/usr/bin/python3', 'main.py', '--dont-print-server']\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-04-21 03:09:48.144\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   4.8 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "\n",
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers attention\n",
            "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.29\n",
            "ComfyUI frontend version: 1.16.9\n",
            "[Prompt Server] web root: /usr/local/lib/python3.11/dist-packages/comfyui_frontend_package/static\n",
            "[rvtools \u001b[0;32mINFO\u001b[0m] RvTools v2 Version: 2.3.8\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "\n",
            "\u001b[92m[rgthree-comfy] Loaded 42 exciting nodes. ðŸŽ‰\u001b[00m\n",
            "\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745205029.285959    3949 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745205029.292497    3949 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m[ComfyUI-Easy-Use] server: \u001b[0mv1.2.8 \u001b[92mLoaded\u001b[0m\n",
            "\u001b[34m[ComfyUI-Easy-Use] web root: \u001b[0m/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use/web_version/v2 \u001b[92mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Impact-Pack (V8.8.1)\n",
            "[Impact Pack] Wildcards loading done.\n",
            "\u001b[34mWAS Node Suite: \u001b[0mOpenCV Python FFMPEG support is enabled\u001b[0m\n",
            "\u001b[34mWAS Node Suite \u001b[93mWarning: \u001b[0m`ffmpeg_bin_path` is not set in `/content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\u001b[0m\n",
            "\u001b[34mWAS Node Suite: \u001b[0mFinished.\u001b[0m \u001b[32mLoaded\u001b[0m \u001b[0m220\u001b[0m \u001b[32mnodes successfully.\u001b[0m\n",
            "\n",
            "\t\u001b[3m\u001b[93m\"Art is not a thing; it is a way.\"\u001b[0m\u001b[3m - Elbert Hubbard\u001b[0m\n",
            "\n",
            "Adding /content/drive/MyDrive/ComfyUI/custom_nodes to sys.path\n",
            "Could not find efficiency nodes\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "Loaded ControlNetPreprocessors nodes from /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "Could not find AdvancedControlNet nodes\n",
            "Could not find AnimateDiff nodes\n",
            "Could not find IPAdapter nodes\n",
            "Could not find VideoHelperSuite nodes\n",
            "Could not load ImpactPack nodes Could not find ImpactPack nodes\n",
            "### Loading: ComfyUI-Impact-Subpack (V1.2.9)\n",
            "[Impact Subpack] ultralytics_bbox: /content/drive/MyDrive/ComfyUI/models/ultralytics/bbox\n",
            "[Impact Subpack] ultralytics_segm: /content/drive/MyDrive/ComfyUI/models/ultralytics/segm\n",
            "------------------------------------------\n",
            "\u001b[34mComfyroll Studio v1.76 : \u001b[92m 175 Nodes Loaded\u001b[0m\n",
            "------------------------------------------\n",
            "** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md\n",
            "** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki\n",
            "------------------------------------------\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "### Loading: ComfyUI-Inspire-Pack (V1.14.1)\n",
            "Loaded Apply Style Model Adjust node - Use this for better control over style vs prompt balance\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "\u001b[92m[tinyterraNodes] \u001b[32mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Manager (V3.30.9)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "### ComfyUI Version: v0.3.29-14-g2c735c13 | Released on '2025-04-20'\n",
            "(pysssss:WD14Tagger) [DEBUG] Available ORT providers: AzureExecutionProvider, CPUExecutionProvider\n",
            "(pysssss:WD14Tagger) [DEBUG] Using ORT providers: CUDAExecutionProvider, CPUExecutionProvider\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "Currently enabled native sdp backends: ['flash', 'math', 'mem_efficient', 'cudnn']\n",
            "Xformers is installed!\n",
            "Flash Attn is not installed!\n",
            "Sage Attn is not installed!\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Align\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Apply_Style_Model_Adjust\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/cg-use-everywhere\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-plasma\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-randomsize\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-image-saver\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inpaint-cropandstitch\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/masquerade\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Noise\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-wd14-tagger\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/jps-nodes\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-florence2\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/execution-inversion-demo-comfyui\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-dynamicprompts\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-various\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ext\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_ultimatesdupscale\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_essentials\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-custom-scripts\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ppm\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-kjnodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyMath\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_RH_FramePack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_ExtraModels\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Chibi-Nodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspire-pack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Comfyroll_CustomNodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-subpack\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-pack\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-tensorops\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/HommageTools\n",
            "   0.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-detail-daemon\n",
            "   0.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_tinyterraNodes\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-art-venture\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-RvTools_v2\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_nyjy\n",
            "   0.7 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_layerstyle\n",
            "   1.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "   1.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-supir\n",
            "   1.8 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui\n",
            "   2.6 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspyrenet-rembg\n",
            "   5.9 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "\n",
            "FETCH ComfyRegistry Data: 5/82\n",
            "FETCH ComfyRegistry Data: 10/82\n",
            "FETCH ComfyRegistry Data: 15/82\n",
            "FETCH ComfyRegistry Data: 20/82\n",
            "FETCH ComfyRegistry Data: 25/82\n",
            "FETCH ComfyRegistry Data: 30/82\n",
            "FETCH ComfyRegistry Data: 35/82\n",
            "FETCH ComfyRegistry Data: 40/82\n",
            "FETCH ComfyRegistry Data: 45/82\n",
            "FETCH ComfyRegistry Data: 50/82\n",
            "FETCH ComfyRegistry Data: 55/82\n",
            "FETCH ComfyRegistry Data: 60/82\n",
            "FETCH ComfyRegistry Data: 65/82\n",
            "FETCH ComfyRegistry Data: 70/82\n",
            "FETCH ComfyRegistry Data: 75/82\n",
            "FETCH ComfyRegistry Data: 80/82\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/remote\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "[Inspire Pack] IPAdapterPlus is not installed.\n",
            "\n",
            "Restarting... [Legacy Mode]\n",
            "\n",
            "\n",
            "Command: ['/usr/bin/python3', 'main.py', '--dont-print-server']\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-04-21 03:18:32.438\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   3.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "\n",
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers attention\n",
            "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.29\n",
            "ComfyUI frontend version: 1.16.9\n",
            "[Prompt Server] web root: /usr/local/lib/python3.11/dist-packages/comfyui_frontend_package/static\n",
            "[rvtools \u001b[0;32mINFO\u001b[0m] RvTools v2 Version: 2.3.8\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "\n",
            "\u001b[92m[rgthree-comfy] Loaded 42 magnificent nodes. ðŸŽ‰\u001b[00m\n",
            "\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745205525.387106    3949 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745205525.393247    3949 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m[ComfyUI-Easy-Use] server: \u001b[0mv1.2.8 \u001b[92mLoaded\u001b[0m\n",
            "\u001b[34m[ComfyUI-Easy-Use] web root: \u001b[0m/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use/web_version/v2 \u001b[92mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Impact-Pack (V8.8.1)\n",
            "[Impact Pack] Wildcards loading done.\n",
            "\u001b[34mWAS Node Suite: \u001b[0mOpenCV Python FFMPEG support is enabled\u001b[0m\n",
            "\u001b[34mWAS Node Suite \u001b[93mWarning: \u001b[0m`ffmpeg_bin_path` is not set in `/content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\u001b[0m\n",
            "\u001b[34mWAS Node Suite: \u001b[0mFinished.\u001b[0m \u001b[32mLoaded\u001b[0m \u001b[0m220\u001b[0m \u001b[32mnodes successfully.\u001b[0m\n",
            "\n",
            "\t\u001b[3m\u001b[93m\"Art is the daughter of freedom.\"\u001b[0m\u001b[3m - Friedrich Schiller\u001b[0m\n",
            "\n",
            "Adding /content/drive/MyDrive/ComfyUI/custom_nodes to sys.path\n",
            "Could not find efficiency nodes\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "Loaded ControlNetPreprocessors nodes from /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "Could not find AdvancedControlNet nodes\n",
            "Could not find AnimateDiff nodes\n",
            "Could not find IPAdapter nodes\n",
            "Could not find VideoHelperSuite nodes\n",
            "Could not load ImpactPack nodes Could not find ImpactPack nodes\n",
            "### Loading: ComfyUI-Impact-Subpack (V1.2.9)\n",
            "[Impact Subpack] ultralytics_bbox: /content/drive/MyDrive/ComfyUI/models/ultralytics/bbox\n",
            "[Impact Subpack] ultralytics_segm: /content/drive/MyDrive/ComfyUI/models/ultralytics/segm\n",
            "------------------------------------------\n",
            "\u001b[34mComfyroll Studio v1.76 : \u001b[92m 175 Nodes Loaded\u001b[0m\n",
            "------------------------------------------\n",
            "** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md\n",
            "** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki\n",
            "------------------------------------------\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "### Loading: ComfyUI-Inspire-Pack (V1.14.1)\n",
            "Loaded Apply Style Model Adjust node - Use this for better control over style vs prompt balance\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "\u001b[92m[tinyterraNodes] \u001b[32mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Manager (V3.30.9)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "### ComfyUI Version: v0.3.29-14-g2c735c13 | Released on '2025-04-20'\n",
            "(pysssss:WD14Tagger) [DEBUG] Available ORT providers: AzureExecutionProvider, CPUExecutionProvider\n",
            "(pysssss:WD14Tagger) [DEBUG] Using ORT providers: CUDAExecutionProvider, CPUExecutionProvider\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "Currently enabled native sdp backends: ['flash', 'math', 'mem_efficient', 'cudnn']\n",
            "Xformers is installed!\n",
            "Flash Attn is not installed!\n",
            "Sage Attn is not installed!\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Align\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-randomsize\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Apply_Style_Model_Adjust\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-plasma\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/cg-use-everywhere\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inpaint-cropandstitch\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/masquerade\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-image-saver\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Noise\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/jps-nodes\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-wd14-tagger\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-florence2\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ext\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_essentials\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/execution-inversion-demo-comfyui\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-dynamicprompts\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_ultimatesdupscale\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-various\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-custom-scripts\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ppm\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyMath\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-kjnodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-subpack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_RH_FramePack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_ExtraModels\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-pack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspire-pack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Comfyroll_CustomNodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Chibi-Nodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-tensorops\n",
            "   0.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-detail-daemon\n",
            "   0.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_tinyterraNodes\n",
            "   0.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_nyjy\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-art-venture\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-RvTools_v2\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_layerstyle\n",
            "   1.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-supir\n",
            "   1.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui\n",
            "   1.6 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "   1.8 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/HommageTools\n",
            "   2.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspyrenet-rembg\n",
            "   4.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "\n",
            "FETCH ComfyRegistry Data: 5/82\n",
            "FETCH ComfyRegistry Data: 10/82\n",
            "FETCH ComfyRegistry Data: 15/82\n",
            "FETCH ComfyRegistry Data: 20/82\n",
            "FETCH ComfyRegistry Data: 25/82\n",
            "FETCH ComfyRegistry Data: 30/82\n",
            "FETCH ComfyRegistry Data: 35/82\n",
            "FETCH ComfyRegistry Data: 40/82\n",
            "[Inspire Pack] IPAdapterPlus is not installed.\n",
            "FETCH ComfyRegistry Data: 45/82\n",
            "FETCH ComfyRegistry Data: 50/82\n",
            "FETCH ComfyRegistry Data: 55/82\n",
            "FETCH ComfyRegistry Data: 60/82\n",
            "FETCH ComfyRegistry Data: 65/82\n",
            "FETCH ComfyRegistry Data: 70/82\n",
            "FETCH ComfyRegistry Data: 75/82\n",
            "FETCH ComfyRegistry Data: 80/82\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/remote\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.1.0 - Processing\n",
            "got prompt\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Generated prompt: A Detailed photograph by SergeMarsh, (30 year old ...\n",
            "Using xformers attention in VAE\n",
            "Using xformers attention in VAE\n",
            "got prompt\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "CLIP/text encoder model load device: cpu, offload device: cpu, current: cpu, dtype: torch.float16\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type FLUX\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Hairy_Art-000001.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (87 > 77). Running this sequence through the model will result in indexing errors\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 10540.125 10539.798950195312 210\n",
            "  4% 1/28 [00:29<13:26, 29.87s/it]FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            " 11% 3/28 [01:27<12:09, 29.18s/it]FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            "Fetching: /content/drive/MyDrive/ComfyUI/custom_nodes/masquerade[ComfyUI-Manager] Failed to check state of the git node pack: \n",
            "/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "Fetching done.\n",
            "send error: Cannot write to closing transport\n",
            "send error: Cannot write to closing transport\n",
            "send error: Cannot write to closing transport\n",
            " 39% 11/28 [05:20<08:13, 29.05s/it]FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            "Updating: comfyui-custom-scriptsInstallation reserved: comfyui-custom-scripts\n",
            "\n",
            "[ComfyUI-Manager] Queued works are completed.\n",
            "{'update': 1}\n",
            "\n",
            "After restarting ComfyUI, please refresh the browser.\n",
            "100% 28/28 [13:33<00:00, 29.05s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1057.31 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.1.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.65A Detailed pho...\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 0\n",
            " 64% 18/28 [05:04<02:48, 16.85s/it]\n",
            "Restarting... [Legacy Mode]\n",
            "\n",
            "\n",
            "Command: ['/usr/bin/python3', 'main.py', '--dont-print-server']\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-04-21 03:46:31.429\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\n",
            "#######################################################################\n",
            "[ComfyUI-Manager] Starting dependency installation/(de)activation for the extension\n",
            "\n",
            "100% 162k/162k [00:00<00:00, 351kB/s] \n",
            "Extracted zip file to /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-custom-scripts\n",
            "'/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-custom-scripts' is moved to '/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-custom-scripts'\n",
            "\n",
            "[ComfyUI-Manager] Startup script completed.\n",
            "#######################################################################\n",
            "\n",
            "[ComfyUI-Manager] Restarting to reapply dependency installation.\n",
            "Command: ['/usr/bin/python3', 'main.py', '--dont-print-server']\n",
            "--------------------------------------------------------------------------\n",
            "\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-04-21 03:47:00.405\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   3.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "\n",
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers attention\n",
            "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.29\n",
            "ComfyUI frontend version: 1.16.9\n",
            "[Prompt Server] web root: /usr/local/lib/python3.11/dist-packages/comfyui_frontend_package/static\n",
            "[rvtools \u001b[0;32mINFO\u001b[0m] RvTools v2 Version: 2.3.8\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "\n",
            "\u001b[92m[rgthree-comfy] Loaded 42 fantastic nodes. ðŸŽ‰\u001b[00m\n",
            "\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745207233.940199    3949 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745207233.946264    3949 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m[ComfyUI-Easy-Use] server: \u001b[0mv1.2.8 \u001b[92mLoaded\u001b[0m\n",
            "\u001b[34m[ComfyUI-Easy-Use] web root: \u001b[0m/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use/web_version/v2 \u001b[92mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Impact-Pack (V8.8.1)\n",
            "[Impact Pack] Wildcards loading done.\n",
            "\u001b[34mWAS Node Suite: \u001b[0mOpenCV Python FFMPEG support is enabled\u001b[0m\n",
            "\u001b[34mWAS Node Suite \u001b[93mWarning: \u001b[0m`ffmpeg_bin_path` is not set in `/content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\u001b[0m\n",
            "\u001b[34mWAS Node Suite: \u001b[0mFinished.\u001b[0m \u001b[32mLoaded\u001b[0m \u001b[0m220\u001b[0m \u001b[32mnodes successfully.\u001b[0m\n",
            "\n",
            "\t\u001b[3m\u001b[93m\"Art is the most intense mode of individualism that the world has known.\"\u001b[0m\u001b[3m - Oscar Wilde\u001b[0m\n",
            "\n",
            "Adding /content/drive/MyDrive/ComfyUI/custom_nodes to sys.path\n",
            "Could not find efficiency nodes\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "Loaded ControlNetPreprocessors nodes from /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "Could not find AdvancedControlNet nodes\n",
            "Could not find AnimateDiff nodes\n",
            "Could not find IPAdapter nodes\n",
            "Could not find VideoHelperSuite nodes\n",
            "Could not load ImpactPack nodes Could not find ImpactPack nodes\n",
            "### Loading: ComfyUI-Impact-Subpack (V1.2.9)\n",
            "[Impact Subpack] ultralytics_bbox: /content/drive/MyDrive/ComfyUI/models/ultralytics/bbox\n",
            "[Impact Subpack] ultralytics_segm: /content/drive/MyDrive/ComfyUI/models/ultralytics/segm\n",
            "------------------------------------------\n",
            "\u001b[34mComfyroll Studio v1.76 : \u001b[92m 175 Nodes Loaded\u001b[0m\n",
            "------------------------------------------\n",
            "** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md\n",
            "** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki\n",
            "------------------------------------------\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "### Loading: ComfyUI-Inspire-Pack (V1.14.1)\n",
            "Loaded Apply Style Model Adjust node - Use this for better control over style vs prompt balance\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "\u001b[92m[tinyterraNodes] \u001b[32mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Manager (V3.30.9)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "### ComfyUI Version: v0.3.29-14-g2c735c13 | Released on '2025-04-20'\n",
            "(pysssss:WD14Tagger) [DEBUG] Available ORT providers: AzureExecutionProvider, CPUExecutionProvider\n",
            "(pysssss:WD14Tagger) [DEBUG] Using ORT providers: CUDAExecutionProvider, CPUExecutionProvider\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "Currently enabled native sdp backends: ['flash', 'math', 'mem_efficient', 'cudnn']\n",
            "Xformers is installed!\n",
            "Flash Attn is not installed!\n",
            "Sage Attn is not installed!\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Align\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-randomsize\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Apply_Style_Model_Adjust\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-image-saver\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-plasma\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/masquerade\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inpaint-cropandstitch\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/cg-use-everywhere\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-wd14-tagger\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Noise\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/jps-nodes\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-florence2\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ext\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/execution-inversion-demo-comfyui\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-dynamicprompts\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-various\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_essentials\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_ultimatesdupscale\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-kjnodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ppm\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_RH_FramePack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyMath\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-subpack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspire-pack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_ExtraModels\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Comfyroll_CustomNodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-tensorops\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Chibi-Nodes\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-pack\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-custom-scripts\n",
            "   0.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-RvTools_v2\n",
            "   0.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_tinyterraNodes\n",
            "   0.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_nyjy\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-detail-daemon\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-art-venture\n",
            "   0.6 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_layerstyle\n",
            "   1.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/HommageTools\n",
            "   1.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-supir\n",
            "   1.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "   1.6 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui\n",
            "   2.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspyrenet-rembg\n",
            "   5.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "\n",
            "FETCH ComfyRegistry Data: 5/82\n",
            "FETCH ComfyRegistry Data: 10/82\n",
            "FETCH ComfyRegistry Data: 15/82\n",
            "FETCH ComfyRegistry Data: 20/82\n",
            "FETCH ComfyRegistry Data: 25/82\n",
            "FETCH ComfyRegistry Data: 30/82\n",
            "FETCH ComfyRegistry Data: 35/82\n",
            "FETCH ComfyRegistry Data: 40/82\n",
            "FETCH ComfyRegistry Data: 45/82\n",
            "FETCH ComfyRegistry Data: 50/82\n",
            "FETCH ComfyRegistry Data: 55/82\n",
            "FETCH ComfyRegistry Data: 60/82\n",
            "FETCH ComfyRegistry Data: 65/82\n",
            "FETCH ComfyRegistry Data: 70/82\n",
            "FETCH ComfyRegistry Data: 75/82\n",
            "FETCH ComfyRegistry Data: 80/82\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/remote\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "[Inspire Pack] IPAdapterPlus is not installed.\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "CLIP/text encoder model load device: cpu, offload device: cpu, current: cpu, dtype: torch.float16\n",
            "\n",
            "HTDynamicPromptNode v1.3.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (106 > 77). Running this sequence through the model will result in indexing errors\n",
            "Generated prompt: A Detailed photograph by SergeMarsh, (30 year old ...\n",
            "Token info: CLIP tokens: 75/120\n",
            "Kept 75/120 tokens (62.5%)\n",
            "Dropped content: \"patterned</w> pillow</w> on</w> a</w> chair</w>...\"\n",
            "Using xformers attention in VAE\n",
            "Using xformers attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type FLUX\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Hairy_Art-000001.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 12556.125 12555.986450195312 187\n",
            "100% 28/28 [06:26<00:00, 13.81s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 624.19 seconds\n",
            "\n",
            "Restarting... [Legacy Mode]\n",
            "\n",
            "\n",
            "Command: ['/usr/bin/python3', 'main.py', '--dont-print-server']\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-04-21 04:06:36.282\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   3.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "\n",
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers attention\n",
            "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.29\n",
            "ComfyUI frontend version: 1.16.9\n",
            "[Prompt Server] web root: /usr/local/lib/python3.11/dist-packages/comfyui_frontend_package/static\n",
            "[rvtools \u001b[0;32mINFO\u001b[0m] RvTools v2 Version: 2.3.8\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "\n",
            "\u001b[92m[rgthree-comfy] Loaded 42 extraordinary nodes. ðŸŽ‰\u001b[00m\n",
            "\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745208410.701088    3949 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745208410.707201    3949 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m[ComfyUI-Easy-Use] server: \u001b[0mv1.2.8 \u001b[92mLoaded\u001b[0m\n",
            "\u001b[34m[ComfyUI-Easy-Use] web root: \u001b[0m/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use/web_version/v2 \u001b[92mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Impact-Pack (V8.8.1)\n",
            "[Impact Pack] Wildcards loading done.\n",
            "\u001b[34mWAS Node Suite: \u001b[0mOpenCV Python FFMPEG support is enabled\u001b[0m\n",
            "\u001b[34mWAS Node Suite \u001b[93mWarning: \u001b[0m`ffmpeg_bin_path` is not set in `/content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\u001b[0m\n",
            "\u001b[34mWAS Node Suite: \u001b[0mFinished.\u001b[0m \u001b[32mLoaded\u001b[0m \u001b[0m220\u001b[0m \u001b[32mnodes successfully.\u001b[0m\n",
            "\n",
            "\t\u001b[3m\u001b[93m\"The future depends on what you do today.\"\u001b[0m\u001b[3m - Mahatma Gandhi\u001b[0m\n",
            "\n",
            "Adding /content/drive/MyDrive/ComfyUI/custom_nodes to sys.path\n",
            "Could not find efficiency nodes\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "Loaded ControlNetPreprocessors nodes from /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "Could not find AdvancedControlNet nodes\n",
            "Could not find AnimateDiff nodes\n",
            "Could not find IPAdapter nodes\n",
            "Could not find VideoHelperSuite nodes\n",
            "Could not load ImpactPack nodes Could not find ImpactPack nodes\n",
            "### Loading: ComfyUI-Impact-Subpack (V1.2.9)\n",
            "[Impact Subpack] ultralytics_bbox: /content/drive/MyDrive/ComfyUI/models/ultralytics/bbox\n",
            "[Impact Subpack] ultralytics_segm: /content/drive/MyDrive/ComfyUI/models/ultralytics/segm\n",
            "------------------------------------------\n",
            "\u001b[34mComfyroll Studio v1.76 : \u001b[92m 175 Nodes Loaded\u001b[0m\n",
            "------------------------------------------\n",
            "** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md\n",
            "** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki\n",
            "------------------------------------------\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "### Loading: ComfyUI-Inspire-Pack (V1.14.1)\n",
            "Loaded Apply Style Model Adjust node - Use this for better control over style vs prompt balance\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "\u001b[92m[tinyterraNodes] \u001b[32mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Manager (V3.30.9)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "### ComfyUI Version: v0.3.29-14-g2c735c13 | Released on '2025-04-20'\n",
            "(pysssss:WD14Tagger) [DEBUG] Available ORT providers: AzureExecutionProvider, CPUExecutionProvider\n",
            "(pysssss:WD14Tagger) [DEBUG] Using ORT providers: CUDAExecutionProvider, CPUExecutionProvider\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "Currently enabled native sdp backends: ['flash', 'math', 'mem_efficient', 'cudnn']\n",
            "Xformers is installed!\n",
            "Flash Attn is not installed!\n",
            "Sage Attn is not installed!\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Align\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-randomsize\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/cg-use-everywhere\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Apply_Style_Model_Adjust\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-plasma\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inpaint-cropandstitch\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-image-saver\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/masquerade\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Noise\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/jps-nodes\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ext\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-wd14-tagger\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-florence2\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_essentials\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-dynamicprompts\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/execution-inversion-demo-comfyui\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-various\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_ultimatesdupscale\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-custom-scripts\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ppm\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_RH_FramePack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyMath\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-subpack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-kjnodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_ExtraModels\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspire-pack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Comfyroll_CustomNodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Chibi-Nodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-tensorops\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-pack\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "   0.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_tinyterraNodes\n",
            "   0.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-RvTools_v2\n",
            "   0.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_nyjy\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-art-venture\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-detail-daemon\n",
            "   0.6 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_layerstyle\n",
            "   1.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/HommageTools\n",
            "   1.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-supir\n",
            "   1.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "   1.6 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui\n",
            "   2.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspyrenet-rembg\n",
            "   5.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "\n",
            "FETCH ComfyRegistry Data: 5/82\n",
            "FETCH ComfyRegistry Data: 10/82\n",
            "FETCH ComfyRegistry Data: 15/82\n",
            "FETCH ComfyRegistry Data: 20/82\n",
            "FETCH ComfyRegistry Data: 25/82\n",
            "FETCH ComfyRegistry Data: 30/82\n",
            "FETCH ComfyRegistry Data: 35/82\n",
            "FETCH ComfyRegistry Data: 40/82\n",
            "FETCH ComfyRegistry Data: 45/82\n",
            "FETCH ComfyRegistry Data: 50/82\n",
            "FETCH ComfyRegistry Data: 55/82\n",
            "FETCH ComfyRegistry Data: 60/82\n",
            "FETCH ComfyRegistry Data: 65/82\n",
            "FETCH ComfyRegistry Data: 70/82\n",
            "FETCH ComfyRegistry Data: 75/82\n",
            "FETCH ComfyRegistry Data: 80/82\n",
            "[Inspire Pack] IPAdapterPlus is not installed.\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/remote\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "CLIP/text encoder model load device: cpu, offload device: cpu, current: cpu, dtype: torch.float16\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (93 > 77). Running this sequence through the model will result in indexing errors\n",
            "Generated prompt: A Detailed photograph by SergeMarsh, (girl:.7) two...\n",
            "Token info: CLIP tokens: 111\n",
            "Using xformers attention in VAE\n",
            "Using xformers attention in VAE\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type FLUX\n",
            "Requested to load Flux\n",
            "loaded partially 12556.125 12555.986450195312 0\n",
            "100% 28/28 [06:17<00:00, 13.50s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 623.35 seconds\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "got prompt\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Generated prompt: A Detailed nude photograph by SergeMarsh, (girl:.7...\n",
            "Token info: CLIP tokens: 110\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "got prompt\n",
            "loaded partially 12698.992 12698.539184570312 0\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:10<04:40, 10.38s/it]got prompt\n",
            "  7% 2/28 [00:20<04:28, 10.32s/it]got prompt\n",
            "got prompt\n",
            " 11% 3/28 [00:30<04:17, 10.30s/it]got prompt\n",
            " 14% 4/28 [00:41<04:06, 10.26s/it]got prompt\n",
            "got prompt\n",
            " 18% 5/28 [00:51<03:54, 10.20s/it]got prompt\n",
            " 21% 6/28 [01:01<03:43, 10.14s/it]got prompt\n",
            " 25% 7/28 [01:11<03:31, 10.09s/it]got prompt\n",
            " 29% 8/28 [01:21<03:21, 10.06s/it]got prompt\n",
            "got prompt\n",
            " 32% 9/28 [01:31<03:11, 10.07s/it]got prompt\n",
            " 36% 10/28 [01:41<03:01, 10.09s/it]got prompt\n",
            " 39% 11/28 [01:51<02:51, 10.12s/it]got prompt\n",
            " 43% 12/28 [02:01<02:41, 10.12s/it]got prompt\n",
            "got prompt\n",
            " 46% 13/28 [02:11<02:31, 10.12s/it]got prompt\n",
            " 50% 14/28 [02:21<02:21, 10.11s/it]got prompt\n",
            " 54% 15/28 [02:32<02:11, 10.09s/it]got prompt\n",
            " 57% 16/28 [02:42<02:01, 10.09s/it]got prompt\n",
            "got prompt\n",
            " 61% 17/28 [02:52<01:50, 10.09s/it]got prompt\n",
            " 64% 18/28 [03:02<01:40, 10.08s/it]got prompt\n",
            " 68% 19/28 [03:12<01:30, 10.06s/it]got prompt\n",
            " 71% 20/28 [03:22<01:20, 10.08s/it]got prompt\n",
            " 75% 21/28 [03:32<01:10, 10.09s/it]got prompt\n",
            "got prompt\n",
            " 79% 22/28 [03:42<01:00, 10.08s/it]got prompt\n",
            " 82% 23/28 [03:52<00:50, 10.09s/it]got prompt\n",
            " 86% 24/28 [04:03<00:40, 10.23s/it]got prompt\n",
            " 89% 25/28 [04:13<00:30, 10.19s/it]got prompt\n",
            " 93% 26/28 [04:23<00:20, 10.18s/it]got prompt\n",
            "got prompt\n",
            " 96% 27/28 [04:33<00:10, 10.16s/it]got prompt\n",
            "100% 28/28 [04:43<00:00, 10.13s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "got prompt\n",
            "Prompt executed in 353.73 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed nude photograph by SergeMarsh, (30 year...\n",
            "Token info: CLIP tokens: 13\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 10878.32 10878.072265625 0\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:24<11:11, 24.86s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  7% 2/28 [00:49<10:48, 24.94s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 11% 3/28 [01:14<10:17, 24.69s/it]got prompt\n",
            "got prompt\n",
            " 14% 4/28 [01:38<09:50, 24.60s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 18% 5/28 [02:03<09:28, 24.72s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 21% 6/28 [02:28<09:02, 24.67s/it]got prompt\n",
            "got prompt\n",
            " 25% 7/28 [02:52<08:36, 24.58s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 29% 8/28 [03:17<08:11, 24.55s/it]got prompt\n",
            "got prompt\n",
            " 32% 9/28 [03:41<07:46, 24.54s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 36% 10/28 [04:06<07:21, 24.53s/it]got prompt\n",
            "got prompt\n",
            " 39% 11/28 [04:30<06:56, 24.52s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 43% 12/28 [04:55<06:32, 24.52s/it]got prompt\n",
            "got prompt\n",
            " 46% 13/28 [05:19<06:07, 24.50s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 50% 14/28 [05:44<05:43, 24.51s/it]got prompt\n",
            "got prompt\n",
            " 54% 15/28 [06:08<05:18, 24.51s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 57% 16/28 [06:33<04:54, 24.52s/it]got prompt\n",
            "got prompt\n",
            " 61% 17/28 [06:57<04:29, 24.49s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 64% 18/28 [07:22<04:04, 24.48s/it]got prompt\n",
            "got prompt\n",
            " 68% 19/28 [07:46<03:40, 24.47s/it]got prompt\n",
            "got prompt\n",
            " 71% 20/28 [08:10<03:15, 24.47s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 75% 21/28 [08:35<02:51, 24.49s/it]got prompt\n",
            "got prompt\n",
            " 79% 22/28 [09:00<02:27, 24.50s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 82% 23/28 [09:24<02:02, 24.47s/it]got prompt\n",
            "got prompt\n",
            " 86% 24/28 [09:48<01:37, 24.46s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 89% 25/28 [10:13<01:13, 24.47s/it]got prompt\n",
            "got prompt\n",
            " 93% 26/28 [10:37<00:48, 24.46s/it]got prompt\n",
            "got prompt\n",
            " 96% 27/28 [11:02<00:24, 24.47s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "100% 28/28 [11:26<00:00, 24.53s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "got prompt\n",
            "Prompt executed in 762.07 seconds\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.6A Detailed nude...\n",
            "Token info: CLIP tokens: 120/168\n",
            "Kept 120/168 tokens (71.4%)\n",
            "Dropped content: \"painting</w> of</w> herself</w> in</w> a</w>...\"\n",
            "\u001b[33m[rgthree-comfy][Power Prompt]\u001b[00m Lora \"FLUX1_Anatomy_Curvy_body_type_for_FLUX_Saggy_natural_breasts.safetensors\" not found, skipping.\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Nipples.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "got prompt\n",
            "loaded partially 9695.6 9695.275512695312 151\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:39<17:37, 39.18s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  4% 1/28 [01:16<34:33, 76.80s/it]\n",
            "Processing interrupted\n",
            "Prompt executed in 143.34 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Generated prompt: A Detailed nude Photograph by Sergey <lora:Sergey_...\n",
            "Token info: CLIP tokens: 19\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Sergey_Marshennikov.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "Processing interrupted\n",
            "Prompt executed in 39.41 seconds\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed nude photograph by SergeMarsh, (girl:.7...\n",
            "Token info: CLIP tokens: 113\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "Requested to load Flux\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "got prompt\n",
            "loaded partially 10878.32 10878.072265625 0\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:25<11:20, 25.22s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  7% 2/28 [00:49<10:48, 24.94s/it]got prompt\n",
            "got prompt\n",
            " 11% 3/28 [01:14<10:16, 24.68s/it]got prompt\n",
            "got prompt\n",
            " 14% 4/28 [01:38<09:50, 24.60s/it]got prompt\n",
            "got prompt\n",
            " 18% 5/28 [02:03<09:26, 24.64s/it]got prompt\n",
            "got prompt\n",
            " 21% 6/28 [02:27<09:00, 24.58s/it]got prompt\n",
            "got prompt\n",
            " 25% 7/28 [02:52<08:35, 24.54s/it]got prompt\n",
            "got prompt\n",
            " 29% 8/28 [03:16<08:10, 24.51s/it]got prompt\n",
            "got prompt\n",
            " 32% 9/28 [03:41<07:45, 24.50s/it]got prompt\n",
            "got prompt\n",
            " 36% 10/28 [04:05<07:20, 24.50s/it]got prompt\n",
            "got prompt\n",
            " 39% 11/28 [04:30<06:56, 24.52s/it]got prompt\n",
            "got prompt\n",
            " 43% 12/28 [04:54<06:32, 24.53s/it]got prompt\n",
            "got prompt\n",
            " 46% 13/28 [05:19<06:08, 24.54s/it]got prompt\n",
            "got prompt\n",
            " 50% 14/28 [05:44<05:43, 24.52s/it]got prompt\n",
            "got prompt\n",
            " 54% 15/28 [06:08<05:18, 24.48s/it]got prompt\n",
            " 57% 16/28 [06:32<04:53, 24.49s/it]got prompt\n",
            "got prompt\n",
            " 61% 17/28 [06:57<04:29, 24.50s/it]got prompt\n",
            "got prompt\n",
            " 64% 18/28 [07:21<04:04, 24.49s/it]got prompt\n",
            "got prompt\n",
            " 68% 19/28 [07:46<03:40, 24.46s/it]got prompt\n",
            "got prompt\n",
            " 71% 20/28 [08:10<03:15, 24.49s/it]got prompt\n",
            "got prompt\n",
            " 75% 21/28 [08:35<02:51, 24.52s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 79% 22/28 [08:59<02:27, 24.50s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 82% 23/28 [09:24<02:02, 24.47s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 86% 24/28 [09:48<01:37, 24.46s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 89% 25/28 [10:13<01:13, 24.50s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 93% 26/28 [10:37<00:48, 24.49s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 96% 27/28 [11:02<00:24, 24.50s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "100% 28/28 [11:26<00:00, 24.53s/it]\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "Requested to load AutoencodingEngine\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "got prompt\n",
            "got prompt\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "0 models unloaded.\n",
            "got prompt\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "Prompt executed in 771.64 seconds\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Generated prompt: A Detailed Photograph:1.2) by SergeMarsh <lora:UNK...\n",
            "Token info: CLIP tokens: 36\n",
            "got prompt\n",
            "got prompt\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "Requested to load Flux\n",
            "Potential memory leak detected with model Flux, doing a full garbage collect, for maximum performance avoid circular references in the model code.\n",
            "WARNING, memory leak with model Flux. Please make sure it is not being referenced from somewhere.\n",
            "loaded partially 10502.0 10501.94140625 210\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:30<13:35, 30.20s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  7% 2/28 [00:59<12:44, 29.39s/it]got prompt\n",
            "got prompt\n",
            " 11% 3/28 [01:27<12:09, 29.16s/it]got prompt\n",
            "got prompt\n",
            " 14% 4/28 [01:57<11:42, 29.25s/it]got prompt\n",
            "got prompt\n",
            "\n",
            "Restarting... [Legacy Mode]\n",
            "\n",
            "\n",
            "Command: ['/usr/bin/python3', 'main.py', '--dont-print-server']\n",
            "[START] Security scan\n",
            "[DONE] Security scan\n",
            "## ComfyUI-Manager: installing dependencies done.\n",
            "** ComfyUI startup time: 2025-04-21 05:02:11.993\n",
            "** Platform: Linux\n",
            "** Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "** Python executable: /usr/bin/python3\n",
            "** ComfyUI Path: /content/drive/MyDrive/ComfyUI\n",
            "** ComfyUI Base Folder Path: /content/drive/MyDrive/ComfyUI\n",
            "** User directory: /content/drive/MyDrive/ComfyUI/user\n",
            "** ComfyUI-Manager config path: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/config.ini\n",
            "** Log path: /content/drive/MyDrive/ComfyUI/user/comfyui.log\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "   3.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "\n",
            "Checkpoint files will always be loaded safely.\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "Using xformers attention\n",
            "Python version: 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "ComfyUI version: 0.3.29\n",
            "ComfyUI frontend version: 1.16.9\n",
            "[Prompt Server] web root: /usr/local/lib/python3.11/dist-packages/comfyui_frontend_package/static\n",
            "[rvtools \u001b[0;32mINFO\u001b[0m] RvTools v2 Version: 2.3.8\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "\n",
            "\u001b[92m[rgthree-comfy] Loaded 42 exciting nodes. ðŸŽ‰\u001b[00m\n",
            "\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745211745.963670    3949 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745211745.969978    3949 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m[ComfyUI-Easy-Use] server: \u001b[0mv1.2.8 \u001b[92mLoaded\u001b[0m\n",
            "\u001b[34m[ComfyUI-Easy-Use] web root: \u001b[0m/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use/web_version/v2 \u001b[92mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Impact-Pack (V8.8.1)\n",
            "[Impact Pack] Wildcards loading done.\n",
            "\u001b[34mWAS Node Suite: \u001b[0mOpenCV Python FFMPEG support is enabled\u001b[0m\n",
            "\u001b[34mWAS Node Suite \u001b[93mWarning: \u001b[0m`ffmpeg_bin_path` is not set in `/content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\u001b[0m\n",
            "\u001b[34mWAS Node Suite: \u001b[0mFinished.\u001b[0m \u001b[32mLoaded\u001b[0m \u001b[0m220\u001b[0m \u001b[32mnodes successfully.\u001b[0m\n",
            "\n",
            "\t\u001b[3m\u001b[93m\"Art is the soul made visible.\"\u001b[0m\u001b[3m - George Crook\u001b[0m\n",
            "\n",
            "Adding /content/drive/MyDrive/ComfyUI/custom_nodes to sys.path\n",
            "Could not find efficiency nodes\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "Loaded ControlNetPreprocessors nodes from /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "Could not find AdvancedControlNet nodes\n",
            "Could not find AnimateDiff nodes\n",
            "Could not find IPAdapter nodes\n",
            "Could not find VideoHelperSuite nodes\n",
            "Could not load ImpactPack nodes Could not find ImpactPack nodes\n",
            "### Loading: ComfyUI-Impact-Subpack (V1.2.9)\n",
            "[Impact Subpack] ultralytics_bbox: /content/drive/MyDrive/ComfyUI/models/ultralytics/bbox\n",
            "[Impact Subpack] ultralytics_segm: /content/drive/MyDrive/ComfyUI/models/ultralytics/segm\n",
            "------------------------------------------\n",
            "\u001b[34mComfyroll Studio v1.76 : \u001b[92m 175 Nodes Loaded\u001b[0m\n",
            "------------------------------------------\n",
            "** For changes, please see patch notes at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/blob/main/Patch_Notes.md\n",
            "** For help, please see the wiki at https://github.com/Suzie1/ComfyUI_Comfyroll_CustomNodes/wiki\n",
            "------------------------------------------\n",
            "Total VRAM 15095 MB, total RAM 52216 MB\n",
            "pytorch version: 2.6.0+cu124\n",
            "xformers version: 0.0.29.post3\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "### Loading: ComfyUI-Inspire-Pack (V1.14.1)\n",
            "Loaded Apply Style Model Adjust node - Use this for better control over style vs prompt balance\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ckpts path: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
            "\u001b[36;20m[/content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
            "\u001b[92m[tinyterraNodes] \u001b[32mLoaded\u001b[0m\n",
            "### Loading: ComfyUI-Manager (V3.30.9)\n",
            "[ComfyUI-Manager] network_mode: public\n",
            "### ComfyUI Version: v0.3.29-14-g2c735c13 | Released on '2025-04-20'\n",
            "(pysssss:WD14Tagger) [DEBUG] Available ORT providers: AzureExecutionProvider, CPUExecutionProvider\n",
            "(pysssss:WD14Tagger) [DEBUG] Using ORT providers: CUDAExecutionProvider, CPUExecutionProvider\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
            "Currently enabled native sdp backends: ['flash', 'math', 'mem_efficient', 'cudnn']\n",
            "Xformers is installed!\n",
            "Flash Attn is not installed!\n",
            "Sage Attn is not installed!\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/websocket_image_save.py\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Align\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Apply_Style_Model_Adjust\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-randomsize\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-image-saver\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/cg-use-everywhere\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfy-plasma\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/masquerade\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inpaint-cropandstitch\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-GGUF\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/jps-nodes\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-florence2\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-wd14-tagger\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ext\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-dynamicprompts\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/execution-inversion-demo-comfyui\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Noise\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_essentials\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-various\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_ultimatesdupscale\n",
            "   0.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-custom-scripts\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-ppm\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_RH_FramePack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-subpack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-kjnodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_ExtraModels\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspire-pack\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_Comfyroll_CustomNodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-Chibi-Nodes\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyMath\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/rgthree-comfy\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-tensorops\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
            "   0.1 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-impact-pack\n",
            "   0.2 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/HommageTools\n",
            "   0.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI-RvTools_v2\n",
            "   0.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/ComfyUI_tinyterraNodes\n",
            "   0.4 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_nyjy\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-art-venture\n",
            "   0.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-detail-daemon\n",
            "   0.7 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-supir\n",
            "   0.7 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui_layerstyle\n",
            "   1.5 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/was-node-suite-comfyui\n",
            "   1.7 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-manager\n",
            "   2.3 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-inspyrenet-rembg\n",
            "   6.0 seconds: /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-easy-use\n",
            "\n",
            "FETCH ComfyRegistry Data: 5/82\n",
            "FETCH ComfyRegistry Data: 10/82\n",
            "FETCH ComfyRegistry Data: 15/82\n",
            "FETCH ComfyRegistry Data: 20/82\n",
            "FETCH ComfyRegistry Data: 25/82\n",
            "FETCH ComfyRegistry Data: 30/82\n",
            "FETCH ComfyRegistry Data: 35/82\n",
            "[Inspire Pack] IPAdapterPlus is not installed.\n",
            "FETCH ComfyRegistry Data: 40/82\n",
            "FETCH ComfyRegistry Data: 45/82\n",
            "FETCH ComfyRegistry Data: 50/82\n",
            "FETCH ComfyRegistry Data: 55/82\n",
            "FETCH ComfyRegistry Data: 60/82\n",
            "FETCH ComfyRegistry Data: 65/82\n",
            "FETCH ComfyRegistry Data: 70/82\n",
            "FETCH ComfyRegistry Data: 75/82\n",
            "FETCH ComfyRegistry Data: 80/82\n",
            "FETCH ComfyRegistry Data [DONE]\n",
            "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/remote\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
            "[ComfyUI-Manager] All startup tasks have been completed.\n",
            "got prompt\n",
            "got prompt\n",
            "Using xformers attention in VAE\n",
            "Using xformers attention in VAE\n",
            "got prompt\n",
            "VAE load device: cuda:0, offload device: cpu, dtype: torch.float32\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "CLIP/text encoder model load device: cpu, offload device: cpu, current: cpu, dtype: torch.float16\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.6>A Detailed Pho...\n",
            "Token info: CLIP tokens: 48\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type FLUX\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "got prompt\n",
            "loaded partially 8524.125 8523.576293945312 231\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:47<21:12, 47.13s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  7% 2/28 [01:32<19:56, 46.03s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 11% 3/28 [02:18<19:10, 46.01s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 14% 4/28 [03:04<18:20, 45.86s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 18% 5/28 [03:49<17:33, 45.79s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 21% 6/28 [04:35<16:46, 45.73s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 25% 7/28 [05:20<15:59, 45.71s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 29% 8/28 [06:06<15:13, 45.68s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 32% 9/28 [06:52<14:27, 45.68s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 36% 10/28 [07:37<13:42, 45.68s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 39% 11/28 [08:23<12:55, 45.64s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 43% 12/28 [09:09<12:10, 45.67s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 46% 13/28 [09:54<11:24, 45.65s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 50% 14/28 [10:40<10:40, 45.74s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 54% 15/28 [11:26<09:54, 45.70s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 57% 16/28 [12:12<09:09, 45.77s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 61% 17/28 [12:58<08:23, 45.75s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 64% 18/28 [13:43<07:36, 45.68s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 68% 19/28 [14:30<06:53, 45.93s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 71% 20/28 [15:15<06:06, 45.84s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 75% 21/28 [16:01<05:20, 45.80s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 79% 22/28 [16:47<04:34, 45.80s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 82% 23/28 [17:33<03:49, 45.92s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 86% 24/28 [18:19<03:03, 45.89s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 89% 25/28 [19:04<02:17, 45.81s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 93% 26/28 [19:50<01:31, 45.76s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 96% 27/28 [20:36<00:45, 45.89s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "100% 28/28 [21:22<00:00, 45.79s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "got prompt\n",
            "Prompt executed in 1524.77 seconds\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.6>A Detailed Pho...\n",
            "Token info: CLIP tokens: 36\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:59<26:53, 59.77s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  7% 2/28 [01:59<25:51, 59.67s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 11% 3/28 [02:58<24:45, 59.41s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 14% 4/28 [03:58<23:47, 59.47s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 18% 5/28 [04:57<22:43, 59.30s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 21% 6/28 [05:56<21:45, 59.36s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 25% 7/28 [06:55<20:44, 59.27s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 29% 8/28 [07:54<19:45, 59.26s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 32% 9/28 [08:54<18:48, 59.37s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 36% 10/28 [09:53<17:47, 59.28s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 39% 11/28 [10:53<16:49, 59.36s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 43% 12/28 [11:52<15:49, 59.33s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 46% 13/28 [12:52<14:53, 59.55s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 50% 14/28 [13:51<13:52, 59.44s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 54% 15/28 [14:50<12:52, 59.39s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 57% 16/28 [15:50<11:52, 59.38s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 61% 17/28 [16:49<10:54, 59.47s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 64% 18/28 [17:49<09:54, 59.45s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 68% 19/28 [18:48<08:54, 59.44s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 71% 20/28 [19:47<07:54, 59.31s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 75% 21/28 [20:46<06:54, 59.21s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 79% 22/28 [21:46<05:56, 59.41s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 82% 23/28 [22:46<04:57, 59.51s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 86% 24/28 [23:45<03:57, 59.35s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 89% 25/28 [24:44<02:58, 59.35s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 93% 26/28 [25:43<01:58, 59.32s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 96% 27/28 [26:43<00:59, 59.30s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "100% 28/28 [27:41<00:00, 59.35s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "got prompt\n",
            "Prompt executed in 1722.82 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (90 > 77). Running this sequence through the model will result in indexing errors\n",
            "Generated prompt: A Detailed nude (watercolor painting:1.2) by Serge...\n",
            "Token info: CLIP tokens: 120\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 8486.0 8485.68359375 232\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:46<20:56, 46.52s/it]got prompt\n",
            "got prompt\n",
            "  7% 2/28 [01:31<19:53, 45.89s/it]got prompt\n",
            "got prompt\n",
            " 11% 3/28 [02:18<19:09, 45.98s/it]got prompt\n",
            "got prompt\n",
            " 14% 4/28 [03:03<18:19, 45.82s/it]got prompt\n",
            "got prompt\n",
            " 18% 5/28 [03:49<17:31, 45.73s/it]got prompt\n",
            "got prompt\n",
            " 21% 6/28 [04:35<16:47, 45.79s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 25% 7/28 [05:20<15:59, 45.67s/it]got prompt\n",
            "got prompt\n",
            " 29% 8/28 [06:06<15:15, 45.79s/it]got prompt\n",
            "got prompt\n",
            " 32% 9/28 [06:52<14:29, 45.74s/it]got prompt\n",
            "got prompt\n",
            " 36% 10/28 [07:37<13:42, 45.70s/it]got prompt\n",
            "got prompt\n",
            " 39% 11/28 [08:23<12:55, 45.61s/it]got prompt\n",
            "got prompt\n",
            " 43% 12/28 [09:08<12:07, 45.49s/it]got prompt\n",
            "got prompt\n",
            " 46% 13/28 [09:53<11:21, 45.42s/it]got prompt\n",
            "got prompt\n",
            " 50% 14/28 [10:38<10:35, 45.37s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 54% 15/28 [11:24<09:49, 45.33s/it]got prompt\n",
            "got prompt\n",
            " 57% 16/28 [12:09<09:03, 45.32s/it]got prompt\n",
            "got prompt\n",
            " 61% 17/28 [12:54<08:18, 45.31s/it]got prompt\n",
            "got prompt\n",
            " 64% 18/28 [13:40<07:33, 45.31s/it]got prompt\n",
            "got prompt\n",
            " 68% 19/28 [14:25<06:47, 45.27s/it]got prompt\n",
            "got prompt\n",
            " 71% 20/28 [15:10<06:02, 45.29s/it]got prompt\n",
            "got prompt\n",
            " 75% 21/28 [15:55<05:16, 45.26s/it]got prompt\n",
            "got prompt\n",
            " 79% 22/28 [16:40<04:31, 45.24s/it]got prompt\n",
            "got prompt\n",
            " 82% 23/28 [17:26<03:46, 45.25s/it]got prompt\n",
            "got prompt\n",
            " 86% 24/28 [18:11<03:00, 45.23s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 89% 25/28 [18:56<02:15, 45.25s/it]got prompt\n",
            "got prompt\n",
            " 93% 26/28 [19:42<01:30, 45.26s/it]got prompt\n",
            "got prompt\n",
            " 96% 27/28 [20:27<00:45, 45.24s/it]got prompt\n",
            "got prompt\n",
            "100% 28/28 [21:12<00:00, 45.44s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "got prompt\n",
            "Prompt executed in 1347.96 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Generated prompt: A Detailed Photograph by Sergey <lora:Sergey_Marsh...\n",
            "Token info: CLIP tokens: 19\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Sergey_Marshennikov.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 8486.0 8485.68359375 232\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:45<20:41, 45.97s/it]got prompt\n",
            "got prompt\n",
            "  7% 2/28 [01:30<19:39, 45.35s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 11% 3/28 [02:16<18:53, 45.35s/it]got prompt\n",
            "got prompt\n",
            " 14% 4/28 [03:01<18:07, 45.32s/it]got prompt\n",
            "got prompt\n",
            " 18% 5/28 [03:46<17:20, 45.25s/it]got prompt\n",
            "got prompt\n",
            " 21% 6/28 [04:31<16:34, 45.20s/it]got prompt\n",
            "got prompt\n",
            " 25% 7/28 [05:16<15:48, 45.19s/it]got prompt\n",
            "got prompt\n",
            " 29% 8/28 [06:02<15:04, 45.20s/it]got prompt\n",
            "got prompt\n",
            " 32% 9/28 [06:47<14:19, 45.24s/it]got prompt\n",
            "got prompt\n",
            " 36% 10/28 [07:32<13:33, 45.20s/it]got prompt\n",
            "got prompt\n",
            " 39% 11/28 [08:17<12:48, 45.22s/it]got prompt\n",
            "got prompt\n",
            " 43% 12/28 [09:03<12:03, 45.24s/it]got prompt\n",
            "got prompt\n",
            " 46% 13/28 [09:48<11:21, 45.40s/it]got prompt\n",
            "got prompt\n",
            " 50% 14/28 [10:34<10:34, 45.35s/it]got prompt\n",
            "got prompt\n",
            " 54% 15/28 [11:19<09:49, 45.31s/it]got prompt\n",
            "got prompt\n",
            " 57% 16/28 [12:04<09:03, 45.26s/it]got prompt\n",
            "got prompt\n",
            " 61% 17/28 [12:49<08:18, 45.28s/it]got prompt\n",
            "got prompt\n",
            " 64% 18/28 [13:35<07:32, 45.27s/it]got prompt\n",
            "got prompt\n",
            " 68% 19/28 [14:20<06:47, 45.26s/it]got prompt\n",
            " 71% 20/28 [15:05<06:01, 45.24s/it]got prompt\n",
            "got prompt\n",
            " 75% 21/28 [15:50<05:16, 45.23s/it]got prompt\n",
            "got prompt\n",
            " 79% 22/28 [16:35<04:31, 45.20s/it]got prompt\n",
            "got prompt\n",
            " 82% 23/28 [17:21<03:46, 45.22s/it]got prompt\n",
            " 86% 24/28 [18:06<03:00, 45.18s/it]got prompt\n",
            "got prompt\n",
            " 89% 25/28 [18:51<02:15, 45.25s/it]got prompt\n",
            "got prompt\n",
            " 93% 26/28 [19:36<01:30, 45.29s/it]got prompt\n",
            "got prompt\n",
            " 96% 27/28 [20:22<00:45, 45.24s/it]got prompt\n",
            "got prompt\n",
            "100% 28/28 [21:07<00:00, 45.26s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1324.55 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed Pho...\n",
            "Token info: CLIP tokens: 120/164\n",
            "Kept 120/164 tokens (73.2%)\n",
            "Dropped content: \"dapp led</w> forest</w> clearing</w> .</w>...\"\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "got prompt\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"nipplediffusion-small-f1.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 3 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 196\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "  4% 1/28 [00:17<07:41, 17.08s/it]got prompt\n",
            " 11% 3/28 [00:51<07:08, 17.15s/it]got prompt\n",
            " 14% 4/28 [01:08<06:49, 17.07s/it]got prompt\n",
            " 21% 6/28 [01:42<06:13, 16.99s/it]got prompt\n",
            " 25% 7/28 [01:59<05:57, 17.04s/it]got prompt\n",
            " 32% 9/28 [02:33<05:23, 17.01s/it]got prompt\n",
            " 36% 10/28 [02:50<05:06, 17.03s/it]got prompt\n",
            " 43% 12/28 [03:24<04:32, 17.02s/it]got prompt\n",
            " 46% 13/28 [03:41<04:15, 17.04s/it]got prompt\n",
            " 54% 15/28 [04:15<03:41, 17.02s/it]got prompt\n",
            " 57% 16/28 [04:32<03:24, 17.04s/it]got prompt\n",
            " 64% 18/28 [05:06<02:50, 17.09s/it]got prompt\n",
            " 68% 19/28 [05:23<02:33, 17.05s/it]got prompt\n",
            " 75% 21/28 [05:57<01:59, 17.02s/it]got prompt\n",
            " 82% 23/28 [06:31<01:24, 16.98s/it]got prompt\n",
            " 86% 24/28 [06:48<01:07, 16.96s/it]got prompt\n",
            "100% 28/28 [07:56<00:00, 17.02s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "Prompt executed in 542.70 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Generated prompt: A Detailed nude Photograph:1.2) by SergeMarsh <lor...\n",
            "Token info: CLIP tokens: 120/155\n",
            "Kept 120/155 tokens (77.4%)\n",
            "Dropped content: \"herself</w> .</w> the</w> background</w> is</w>...\"\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Hairy_Art-000001.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "Failed to validate prompt for output 9:\n",
            "* UnetLoaderGGUF 49:\n",
            "  - Value not in list: unet_name: 'flux1-dev-Q8_0.gguf' not in (list of length 82)\n",
            "* Load Lora 50:\n",
            "  - Value not in list: lora_name: 'FLUX1/SergeMarshFlux.safetensors' not in (list of length 1641)\n",
            "Output will be ignored\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:59<26:51, 59.69s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  7% 2/28 [01:58<25:40, 59.23s/it]got prompt\n",
            "got prompt\n",
            " 11% 3/28 [02:57<24:37, 59.11s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 14% 4/28 [03:56<23:38, 59.09s/it]got prompt\n",
            "got prompt\n",
            " 18% 5/28 [04:55<22:35, 58.95s/it]got prompt\n",
            "got prompt\n",
            " 21% 6/28 [05:54<21:38, 59.03s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 25% 7/28 [06:53<20:40, 59.05s/it]got prompt\n",
            "got prompt\n",
            " 29% 8/28 [07:52<19:40, 59.02s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 32% 9/28 [08:51<18:41, 59.05s/it]got prompt\n",
            "got prompt\n",
            " 36% 10/28 [09:50<17:42, 59.02s/it]got prompt\n",
            "got prompt\n",
            " 39% 11/28 [10:49<16:43, 59.01s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 43% 12/28 [11:48<15:43, 58.97s/it]got prompt\n",
            "got prompt\n",
            " 46% 13/28 [12:47<14:45, 59.01s/it]got prompt\n",
            "got prompt\n",
            " 50% 14/28 [13:46<13:46, 59.02s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 54% 15/28 [14:45<12:46, 58.99s/it]got prompt\n",
            "got prompt\n",
            " 57% 16/28 [15:44<11:47, 58.98s/it]got prompt\n",
            "got prompt\n",
            " 61% 17/28 [16:43<10:47, 58.89s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 64% 18/28 [17:42<09:49, 58.92s/it]got prompt\n",
            "got prompt\n",
            " 68% 19/28 [18:41<08:50, 58.90s/it]got prompt\n",
            "got prompt\n",
            " 71% 20/28 [19:40<07:51, 58.92s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 75% 21/28 [20:39<06:53, 59.02s/it]got prompt\n",
            "got prompt\n",
            " 79% 22/28 [21:38<05:53, 58.94s/it]got prompt\n",
            "got prompt\n",
            " 82% 23/28 [22:36<04:54, 58.93s/it]got prompt\n",
            "got prompt\n",
            " 86% 24/28 [23:35<03:55, 58.89s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 89% 25/28 [24:34<02:56, 58.86s/it]got prompt\n",
            "got prompt\n",
            " 93% 26/28 [25:33<01:57, 58.84s/it]got prompt\n",
            "got prompt\n",
            " 96% 27/28 [26:31<00:58, 58.76s/it]got prompt\n",
            "got prompt\n",
            "100% 28/28 [27:30<00:00, 58.95s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "got prompt\n",
            "Prompt executed in 1713.68 seconds\n",
            "New prompt: a portrait by SergeMarss of a young woman standing in a room with a dark background. She is wearing a long, flowing white dress with a high neckline and long sleeves. The dress is made of a light-colored fabric with a subtle sheen. The woman has blonde hair styled in loose waves and is wearing an elaborate headpiece with a large, ornate headpiece on top. The headpiece is made up of multiple layers of fabric, with the top layer being the largest and the bottom layer being smaller. The overall mood of elegant and regal.\n",
            "Prompt executed in 1.86 seconds\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "CLIP/text encoder model load device: cpu, offload device: cpu, current: cpu, dtype: torch.float16\n",
            "got prompt\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (157 > 77). Running this sequence through the model will result in indexing errors\n",
            "Generated prompt: A Detailed nude Photograph:1.2) by SergeMarsh <lor...\n",
            "Token info: CLIP tokens: 120/155\n",
            "Kept 120/155 tokens (77.4%)\n",
            "Dropped content: \"herself</w> .</w> the</w> background</w> is</w>...\"\n",
            "model weight dtype torch.float16, manual cast: None\n",
            "model_type FLUX\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Hairy_Art-000001.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  4% 1/28 [01:00<27:11, 60.44s/it]got prompt\n",
            "got prompt\n",
            "  7% 2/28 [01:59<25:49, 59.58s/it]got prompt\n",
            "got prompt\n",
            " 11% 3/28 [02:58<24:41, 59.26s/it]got prompt\n",
            "got prompt\n",
            " 14% 4/28 [03:57<23:38, 59.09s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 18% 5/28 [04:56<22:37, 59.01s/it]got prompt\n",
            "got prompt\n",
            " 21% 6/28 [05:55<21:38, 59.01s/it]got prompt\n",
            "got prompt\n",
            " 25% 7/28 [06:53<20:38, 58.99s/it]got prompt\n",
            "got prompt\n",
            " 29% 8/28 [07:53<19:42, 59.14s/it]got prompt\n",
            "got prompt\n",
            " 32% 9/28 [08:52<18:44, 59.18s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 36% 10/28 [09:51<17:43, 59.09s/it]got prompt\n",
            "got prompt\n",
            " 39% 11/28 [10:50<16:45, 59.13s/it]got prompt\n",
            "got prompt\n",
            " 43% 12/28 [11:49<15:45, 59.07s/it]got prompt\n",
            "got prompt\n",
            " 46% 13/28 [12:48<14:44, 58.98s/it]got prompt\n",
            "got prompt\n",
            " 50% 14/28 [13:47<13:45, 58.97s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 54% 15/28 [14:47<12:49, 59.19s/it]got prompt\n",
            "got prompt\n",
            " 57% 16/28 [15:46<11:49, 59.10s/it]got prompt\n",
            "got prompt\n",
            " 61% 17/28 [16:45<10:49, 59.06s/it]got prompt\n",
            "got prompt\n",
            " 64% 18/28 [17:43<09:50, 59.04s/it]got prompt\n",
            "got prompt\n",
            " 68% 19/28 [18:42<08:50, 58.98s/it]got prompt\n",
            "got prompt\n",
            " 71% 20/28 [19:42<07:52, 59.09s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 75% 21/28 [20:41<06:53, 59.11s/it]got prompt\n",
            "got prompt\n",
            " 79% 22/28 [21:40<05:54, 59.06s/it]got prompt\n",
            "got prompt\n",
            " 82% 23/28 [22:39<04:55, 59.04s/it]got prompt\n",
            "got prompt\n",
            " 86% 24/28 [23:38<03:55, 58.95s/it]got prompt\n",
            "got prompt\n",
            " 89% 25/28 [24:37<02:57, 59.05s/it]got prompt\n",
            "got prompt\n",
            " 93% 26/28 [25:36<01:58, 59.05s/it]got prompt\n",
            "got prompt\n",
            " 96% 27/28 [26:35<00:59, 59.01s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "100% 28/28 [27:34<00:00, 59.07s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "got prompt\n",
            "Prompt executed in 1893.75 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed nud...\n",
            "Token info: CLIP tokens: 44\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 8486.0 8485.68359375 232\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "  4% 1/28 [00:46<20:56, 46.56s/it]got prompt\n",
            "got prompt\n",
            "  7% 2/28 [01:31<19:51, 45.84s/it]got prompt\n",
            "got prompt\n",
            " 11% 3/28 [02:18<19:09, 45.99s/it]got prompt\n",
            " 14% 4/28 [03:04<18:26, 46.10s/it]got prompt\n",
            "got prompt\n",
            " 18% 5/28 [03:50<17:38, 46.01s/it]got prompt\n",
            "got prompt\n",
            " 21% 6/28 [04:36<16:51, 45.97s/it]got prompt\n",
            "got prompt\n",
            " 25% 7/28 [05:21<16:04, 45.92s/it]got prompt\n",
            " 29% 8/28 [06:07<15:18, 45.91s/it]got prompt\n",
            "got prompt\n",
            " 32% 9/28 [06:53<14:33, 45.96s/it]got prompt\n",
            "got prompt\n",
            " 36% 10/28 [07:39<13:45, 45.87s/it]got prompt\n",
            " 39% 11/28 [08:25<12:58, 45.79s/it]got prompt\n",
            "got prompt\n",
            " 43% 12/28 [09:10<12:12, 45.77s/it]got prompt\n",
            " 46% 13/28 [09:56<11:27, 45.81s/it]got prompt\n",
            "got prompt\n",
            " 50% 14/28 [10:43<10:43, 45.97s/it]got prompt\n",
            "got prompt\n",
            " 54% 15/28 [11:28<09:57, 45.93s/it]got prompt\n",
            " 57% 16/28 [12:14<09:10, 45.89s/it]got prompt\n",
            "got prompt\n",
            " 61% 17/28 [13:00<08:24, 45.87s/it]got prompt\n",
            "got prompt\n",
            " 64% 18/28 [13:46<07:38, 45.87s/it]got prompt\n",
            " 68% 19/28 [14:32<06:52, 45.83s/it]got prompt\n",
            "got prompt\n",
            " 71% 20/28 [15:18<06:07, 45.96s/it]got prompt\n",
            "got prompt\n",
            " 75% 21/28 [16:04<05:21, 45.92s/it]got prompt\n",
            " 79% 22/28 [16:49<04:34, 45.83s/it]got prompt\n",
            "got prompt\n",
            " 82% 23/28 [17:35<03:49, 45.86s/it]got prompt\n",
            "got prompt\n",
            " 86% 24/28 [18:21<03:03, 45.95s/it]got prompt\n",
            " 89% 25/28 [19:07<02:17, 45.92s/it]got prompt\n",
            "got prompt\n",
            " 93% 26/28 [19:53<01:31, 45.93s/it]got prompt\n",
            " 96% 27/28 [20:39<00:45, 45.86s/it]got prompt\n",
            "got prompt\n",
            "100% 28/28 [21:25<00:00, 45.90s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "got prompt\n",
            "Prompt executed in 1363.11 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed Photograph by Sergey <lora:Sergey_Marsh...\n",
            "Token info: CLIP tokens: 18\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Sergey_Marshennikov.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 196\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "  7% 2/28 [00:33<07:14, 16.73s/it]got prompt\n",
            " 11% 3/28 [00:50<06:58, 16.72s/it]got prompt\n",
            " 18% 5/28 [01:22<06:17, 16.42s/it]got prompt\n",
            " 25% 7/28 [01:56<05:48, 16.59s/it]got prompt\n",
            " 32% 9/28 [02:28<05:13, 16.49s/it]got prompt\n",
            " 36% 10/28 [02:45<04:57, 16.54s/it]got prompt\n",
            " 43% 12/28 [03:18<04:23, 16.48s/it]got prompt\n",
            " 50% 14/28 [03:51<03:50, 16.45s/it]got prompt\n",
            " 57% 16/28 [04:24<03:17, 16.46s/it]got prompt\n",
            " 61% 17/28 [04:40<03:01, 16.49s/it]got prompt\n",
            " 68% 19/28 [05:13<02:28, 16.47s/it]got prompt\n",
            " 75% 21/28 [05:47<01:55, 16.56s/it]got prompt\n",
            " 82% 23/28 [06:20<01:22, 16.50s/it]got prompt\n",
            " 86% 24/28 [06:36<01:06, 16.53s/it]got prompt\n",
            " 93% 26/28 [07:09<00:32, 16.49s/it]got prompt\n",
            "100% 28/28 [07:42<00:00, 16.52s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "got prompt\n",
            "Prompt executed in 512.19 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed nud...\n",
            "Token info: CLIP tokens: 53\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 9050.48 9047.228637695312 226\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "  4% 1/28 [00:41<18:34, 41.28s/it]got prompt\n",
            "got prompt\n",
            "  7% 2/28 [01:21<17:33, 40.51s/it]got prompt\n",
            " 11% 3/28 [02:01<16:53, 40.54s/it]got prompt\n",
            "got prompt\n",
            " 14% 4/28 [02:42<16:13, 40.56s/it]got prompt\n",
            " 18% 5/28 [03:22<15:29, 40.41s/it]got prompt\n",
            " 21% 6/28 [04:02<14:47, 40.36s/it]got prompt\n",
            "got prompt\n",
            " 25% 7/28 [04:43<14:13, 40.62s/it]got prompt\n",
            " 29% 8/28 [05:24<13:30, 40.54s/it]got prompt\n",
            " 32% 9/28 [06:04<12:49, 40.50s/it]got prompt\n",
            "got prompt\n",
            " 36% 10/28 [06:45<12:09, 40.51s/it]got prompt\n",
            " 39% 11/28 [07:25<11:27, 40.45s/it]got prompt\n",
            " 43% 12/28 [08:06<10:47, 40.45s/it]got prompt\n",
            "got prompt\n",
            " 46% 13/28 [08:47<10:09, 40.67s/it]got prompt\n",
            " 50% 14/28 [09:27<09:27, 40.51s/it]got prompt\n",
            "got prompt\n",
            " 54% 15/28 [10:07<08:46, 40.52s/it]got prompt\n",
            " 57% 16/28 [10:48<08:06, 40.52s/it]got prompt\n",
            " 61% 17/28 [11:29<07:26, 40.64s/it]got prompt\n",
            "got prompt\n",
            " 64% 18/28 [12:09<06:45, 40.57s/it]got prompt\n",
            " 68% 19/28 [12:49<06:04, 40.46s/it]got prompt\n",
            " 71% 20/28 [13:29<05:22, 40.30s/it]got prompt\n",
            "got prompt\n",
            " 75% 21/28 [14:11<04:44, 40.57s/it]got prompt\n",
            " 79% 22/28 [14:51<04:02, 40.45s/it]got prompt\n",
            " 82% 23/28 [15:31<03:22, 40.42s/it]got prompt\n",
            "got prompt\n",
            " 86% 24/28 [16:12<02:41, 40.44s/it]got prompt\n",
            " 89% 25/28 [16:52<02:01, 40.38s/it]got prompt\n",
            " 93% 26/28 [17:32<01:20, 40.41s/it]got prompt\n",
            "got prompt\n",
            " 96% 27/28 [18:13<00:40, 40.44s/it]got prompt\n",
            "100% 28/28 [18:53<00:00, 40.48s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "got prompt\n",
            "Prompt executed in 1191.84 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed nud...\n",
            "Token info: CLIP tokens: 120/130\n",
            "Kept 120/130 tokens (92.3%)\n",
            "Dropped content: \"fluid</w> .</w> the</w> image</w> is</w>...\"\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "got prompt\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "  4% 1/28 [00:59<26:56, 59.87s/it]got prompt\n",
            "got prompt\n",
            "  7% 2/28 [01:59<25:55, 59.82s/it]got prompt\n",
            "got prompt\n",
            " 11% 3/28 [02:58<24:50, 59.60s/it]got prompt\n",
            "got prompt\n",
            " 14% 4/28 [03:58<23:53, 59.72s/it]got prompt\n",
            "got prompt\n",
            " 18% 5/28 [04:58<22:50, 59.57s/it]got prompt\n",
            "got prompt\n",
            " 21% 6/28 [05:57<21:49, 59.51s/it]got prompt\n",
            "got prompt\n",
            " 25% 7/28 [06:56<20:48, 59.46s/it]got prompt\n",
            "got prompt\n",
            " 29% 8/28 [07:56<19:46, 59.34s/it]got prompt\n",
            "got prompt\n",
            " 32% 9/28 [08:55<18:46, 59.30s/it]got prompt\n",
            " 36% 10/28 [09:55<17:49, 59.44s/it]got prompt\n",
            "got prompt\n",
            " 39% 11/28 [10:54<16:51, 59.49s/it]got prompt\n",
            "got prompt\n",
            " 43% 12/28 [11:53<15:49, 59.36s/it]got prompt\n",
            "got prompt\n",
            " 46% 13/28 [12:53<14:51, 59.47s/it]got prompt\n",
            "got prompt\n",
            " 50% 14/28 [13:53<13:53, 59.53s/it]got prompt\n",
            "got prompt\n",
            " 54% 15/28 [14:52<12:51, 59.38s/it]got prompt\n",
            "got prompt\n",
            " 57% 16/28 [15:51<11:51, 59.32s/it]got prompt\n",
            " 61% 17/28 [16:50<10:51, 59.27s/it]got prompt\n",
            "got prompt\n",
            " 64% 18/28 [17:49<09:51, 59.17s/it]got prompt\n",
            "got prompt\n",
            " 68% 19/28 [18:49<08:55, 59.51s/it]got prompt\n",
            "got prompt\n",
            " 71% 20/28 [19:48<07:55, 59.42s/it]got prompt\n",
            "got prompt\n",
            " 75% 21/28 [20:49<06:57, 59.66s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 79% 22/28 [21:48<05:57, 59.54s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 82% 23/28 [22:47<04:57, 59.54s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 86% 24/28 [23:48<03:58, 59.72s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 89% 25/28 [24:47<02:59, 59.75s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 93% 26/28 [25:47<01:59, 59.62s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 96% 27/28 [26:47<00:59, 59.72s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "100% 28/28 [27:46<00:00, 59.52s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "got prompt\n",
            "Prompt executed in 1751.51 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed Photograph:1.2) by SergeMarsh <lora:UNK...\n",
            "Token info: CLIP tokens: 31\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "got prompt\n",
            "loaded partially 9050.48 9047.228637695312 226\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:40<18:21, 40.81s/it]got prompt\n",
            "got prompt\n",
            "  7% 2/28 [01:20<17:22, 40.10s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "100% 28/28 [18:35<00:00, 39.86s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1174.16 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed Pho...\n",
            "Token info: CLIP tokens: 49\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 196\n",
            "100% 28/28 [07:47<00:00, 16.70s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "Prompt executed in 517.50 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed nud...\n",
            "Token info: CLIP tokens: 50\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 8486.0 8485.68359375 232\n",
            "100% 28/28 [21:20<00:00, 45.72s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1340.35 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed nud...\n",
            "Token info: CLIP tokens: 41\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 196\n",
            "100% 28/28 [07:47<00:00, 16.69s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "Prompt executed in 534.97 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: \n",
            "Token info: CLIP tokens: 0\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 0\n",
            "100% 28/28 [07:22<00:00, 15.79s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "Prompt executed in 493.66 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed Photograph:1.2) by SergeMarsh <lora:UNK...\n",
            "Token info: CLIP tokens: 120/133\n",
            "Kept 120/133 tokens (90.2%)\n",
            "Dropped content: \"her</w> pose</w> is</w> fluid</w> .</w>...\"\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Nipples.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 196\n",
            "100% 28/28 [07:46<00:00, 16.66s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "Prompt executed in 518.11 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: \n",
            "Token info: CLIP tokens: 0\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 0\n",
            "100% 28/28 [26:34<00:00, 56.95s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1660.53 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed nude Photograph by SergeMarsh <lora:UNK...\n",
            "Token info: CLIP tokens: 21\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 9050.48 9047.228637695312 226\n",
            "100% 28/28 [18:35<00:00, 39.83s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1171.48 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed Pho...\n",
            "Token info: CLIP tokens: 120/167\n",
            "Kept 120/167 tokens (71.9%)\n",
            "Dropped content: \"photo</w> frames</w> and</w> ornate</w> mirrors</w>...\"\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 8486.0 8485.68359375 232\n",
            "100% 28/28 [21:21<00:00, 45.78s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1340.70 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed nude Photograph:1.2) by SergeMarsh <lor...\n",
            "Token info: CLIP tokens: 120/145\n",
            "Kept 120/145 tokens (82.8%)\n",
            "Dropped content: \"and</w> detailed</w> and</w> in</w> the</w>...\"\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Nipples.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            " 68% 19/28 [18:38<08:48, 58.77s/it]got prompt\n",
            "got prompt\n",
            " 71% 20/28 [19:37<07:50, 58.79s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 75% 21/28 [20:36<06:53, 59.02s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 79% 22/28 [21:36<05:54, 59.15s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 82% 23/28 [22:35<04:55, 59.17s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 86% 24/28 [23:35<03:57, 59.35s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 89% 25/28 [24:34<02:58, 59.45s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "100% 28/28 [27:31<00:00, 58.99s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1713.87 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Generated prompt: A Detailed Photograph by SergeMarsh <lora:UNKNOWN/...\n",
            "Token info: CLIP tokens: 20\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 8486.0 8485.68359375 232\n",
            "100% 28/28 [21:08<00:00, 45.29s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1326.74 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: \n",
            "Token info: CLIP tokens: 0\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 10405.232 10397.316528320312 0\n",
            "100% 28/28 [12:31<00:00, 26.85s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 457.671875 319.7467155456543 True\n",
            "Prompt executed in 808.50 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed (Ph...\n",
            "Token info: CLIP tokens: 120/168\n",
            "Kept 120/168 tokens (71.4%)\n",
            "Dropped content: \"medieval</w> castle</w> 's</w> chamber</w> .</w>...\"\n",
            "\u001b[33m[rgthree-comfy][Power Prompt]\u001b[00m Lora \"FLUX1_Anatomy_really_sagging_breasts.safetensors\" not found, skipping.\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"nipplediffusion-f1.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 3 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            "100% 28/28 [27:44<00:00, 59.45s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1760.41 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed nude (Photograph:1.2) by SergeMarsh <lo...\n",
            "Token info: CLIP tokens: 120/134\n",
            "Kept 120/134 tokens (89.6%)\n",
            "Dropped content: \".</w> her</w> pose</w> is</w> dramatic</w>...\"\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m Skipping \"UNKNOWN/SergeMarshFlux\" with strength of zero\u001b[00m\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 0\n",
            "100% 28/28 [26:37<00:00, 57.04s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1681.08 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed (Ph...\n",
            "Token info: CLIP tokens: 120\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m Skipping \"UNKNOWN/SergeMarshFlux\" with strength of zero\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 196\n",
            "100% 28/28 [07:39<00:00, 16.43s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "Prompt executed in 525.01 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed (Ph...\n",
            "Token info: CLIP tokens: 120/151\n",
            "Kept 120/151 tokens (79.5%)\n",
            "Dropped content: \"and</w> detailed</w> and</w> in</w> the</w>...\"\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Hairy_Art-000001.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 3 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 9050.48 9047.228637695312 226\n",
            "100% 28/28 [19:00<00:00, 40.73s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1215.50 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed (wa...\n",
            "Token info: CLIP tokens: 36\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Sergey_Marshennikov.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 196\n",
            "100% 28/28 [07:47<00:00, 16.68s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "Prompt executed in 533.09 seconds\n",
            "got prompt\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Created new prompt generator for: ${composition={0.5::{0.4::full...\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed nud...\n",
            "Token info: CLIP tokens: 37\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 10405.232 10397.316528320312 211\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  4% 1/28 [00:29<13:09, 29.24s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            "  7% 2/28 [00:57<12:20, 28.48s/it]got prompt\n",
            "got prompt\n",
            " 11% 3/28 [01:25<11:47, 28.30s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 14% 4/28 [01:53<11:21, 28.39s/it]got prompt\n",
            "got prompt\n",
            " 18% 5/28 [02:22<10:52, 28.35s/it]got prompt\n",
            "got prompt\n",
            "got prompt\n",
            " 21% 6/28 [02:50<10:22, 28.28s/it]got prompt\n",
            "got prompt\n",
            " 25% 7/28 [03:18<09:54, 28.32s/it]got prompt\n",
            "got prompt\n",
            " 29% 8/28 [03:46<09:25, 28.29s/it]got prompt\n",
            "got prompt\n",
            " 32% 9/28 [04:15<08:56, 28.26s/it]got prompt\n",
            "got prompt\n",
            " 36% 10/28 [04:43<08:28, 28.25s/it]got prompt\n",
            "got prompt\n",
            " 39% 11/28 [05:11<08:00, 28.24s/it]got prompt\n",
            " 43% 12/28 [05:39<07:31, 28.24s/it]got prompt\n",
            "got prompt\n",
            " 46% 13/28 [06:07<07:03, 28.23s/it]got prompt\n",
            "got prompt\n",
            " 50% 14/28 [06:36<06:34, 28.21s/it]got prompt\n",
            "got prompt\n",
            " 54% 15/28 [07:04<06:06, 28.22s/it]got prompt\n",
            "got prompt\n",
            " 57% 16/28 [07:32<05:38, 28.22s/it]got prompt\n",
            "got prompt\n",
            " 61% 17/28 [08:00<05:10, 28.24s/it]got prompt\n",
            "got prompt\n",
            " 64% 18/28 [08:29<04:42, 28.24s/it]got prompt\n",
            "got prompt\n",
            " 68% 19/28 [08:57<04:14, 28.24s/it]got prompt\n",
            " 71% 20/28 [09:25<03:45, 28.25s/it]got prompt\n",
            "got prompt\n",
            " 75% 21/28 [09:53<03:17, 28.25s/it]got prompt\n",
            "got prompt\n",
            " 79% 22/28 [10:22<02:49, 28.23s/it]got prompt\n",
            "got prompt\n",
            " 82% 23/28 [10:50<02:22, 28.41s/it]got prompt\n",
            "got prompt\n",
            " 86% 24/28 [11:19<01:53, 28.37s/it]got prompt\n",
            "got prompt\n",
            " 89% 25/28 [11:47<01:24, 28.32s/it]got prompt\n",
            " 93% 26/28 [12:15<00:56, 28.29s/it]got prompt\n",
            "got prompt\n",
            " 96% 27/28 [12:43<00:28, 28.26s/it]got prompt\n",
            "got prompt\n",
            "100% 28/28 [13:11<00:00, 28.29s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 457.671875 319.7467155456543 True\n",
            "got prompt\n",
            "Prompt executed in 844.52 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: \n",
            "Token info: CLIP tokens: 0\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 0\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "  4% 1/28 [00:15<07:08, 15.89s/it]got prompt\n",
            "  7% 2/28 [00:32<06:58, 16.09s/it]got prompt\n",
            " 11% 3/28 [00:48<06:41, 16.04s/it]got prompt\n",
            " 14% 4/28 [01:03<06:22, 15.92s/it]got prompt\n",
            " 18% 5/28 [01:19<06:04, 15.83s/it]got prompt\n",
            " 21% 6/28 [01:35<05:47, 15.81s/it]got prompt\n",
            " 25% 7/28 [01:51<05:32, 15.84s/it]got prompt\n",
            " 29% 8/28 [02:07<05:17, 15.87s/it]got prompt\n",
            " 32% 9/28 [02:22<05:01, 15.87s/it]got prompt\n",
            " 36% 10/28 [02:38<04:45, 15.84s/it]got prompt\n",
            " 39% 11/28 [02:54<04:29, 15.83s/it]got prompt\n",
            " 43% 12/28 [03:10<04:13, 15.82s/it]got prompt\n",
            " 46% 13/28 [03:26<03:57, 15.83s/it]got prompt\n",
            " 54% 15/28 [03:57<03:26, 15.85s/it]got prompt\n",
            " 57% 16/28 [04:13<03:10, 15.85s/it]got prompt\n",
            " 61% 17/28 [04:30<02:56, 16.02s/it]got prompt\n",
            " 64% 18/28 [04:46<02:39, 15.98s/it]got prompt\n",
            " 68% 19/28 [05:02<02:23, 15.96s/it]got prompt\n",
            " 71% 20/28 [05:17<02:07, 15.95s/it]got prompt\n",
            " 75% 21/28 [05:33<01:51, 15.92s/it]got prompt\n",
            " 79% 22/28 [05:49<01:35, 15.89s/it]got prompt\n",
            " 82% 23/28 [06:05<01:19, 15.88s/it]got prompt\n",
            " 86% 24/28 [06:21<01:03, 15.86s/it]got prompt\n",
            " 89% 25/28 [06:37<00:47, 15.84s/it]got prompt\n",
            " 93% 26/28 [06:52<00:31, 15.83s/it]got prompt\n",
            " 96% 27/28 [07:08<00:15, 15.83s/it]got prompt\n",
            "100% 28/28 [07:24<00:00, 15.88s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "Prompt executed in 495.20 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed Pho...\n",
            "Token info: CLIP tokens: 35\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Sergey_Marshennikov.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "got prompt\n",
            "got prompt\n",
            "Requested to load Flux\n",
            "got prompt\n",
            "loaded partially 10405.232 10397.316528320312 211\n",
            "  0% 0/28 [00:00<?, ?it/s]got prompt\n",
            "  4% 1/28 [00:28<12:58, 28.85s/it]got prompt\n",
            "got prompt\n",
            "  7% 2/28 [00:57<12:22, 28.55s/it]got prompt\n",
            " 11% 3/28 [01:25<11:48, 28.33s/it]got prompt\n",
            "got prompt\n",
            " 14% 4/28 [01:53<11:20, 28.35s/it]got prompt\n",
            "got prompt\n",
            " 18% 5/28 [02:21<10:50, 28.30s/it]got prompt\n",
            " 21% 6/28 [02:50<10:21, 28.27s/it]got prompt\n",
            "got prompt\n",
            " 25% 7/28 [03:18<09:54, 28.33s/it]got prompt\n",
            "got prompt\n",
            " 29% 8/28 [03:46<09:27, 28.38s/it]got prompt\n",
            " 32% 9/28 [04:15<08:58, 28.33s/it]got prompt\n",
            "got prompt\n",
            " 36% 10/28 [04:43<08:29, 28.29s/it]got prompt\n",
            " 39% 11/28 [05:11<08:00, 28.25s/it]got prompt\n",
            "got prompt\n",
            " 43% 12/28 [05:39<07:32, 28.28s/it]got prompt\n",
            " 46% 13/28 [06:08<07:04, 28.29s/it]got prompt\n",
            " 50% 14/28 [06:37<06:38, 28.44s/it]got prompt\n",
            " 57% 16/28 [07:33<05:40, 28.40s/it]got prompt\n",
            " 61% 17/28 [08:01<05:11, 28.34s/it]got prompt\n",
            " 64% 18/28 [08:30<04:43, 28.31s/it]got prompt\n",
            " 68% 19/28 [08:58<04:14, 28.27s/it]got prompt\n",
            " 75% 21/28 [09:54<03:17, 28.27s/it]got prompt\n",
            " 86% 24/28 [11:19<01:53, 28.27s/it]got prompt\n",
            " 96% 27/28 [12:44<00:28, 28.22s/it]got prompt\n",
            "invalid prompt: {'type': 'prompt_no_outputs', 'message': 'Prompt has no outputs', 'details': '', 'extra_info': {}}\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "100% 28/28 [13:12<00:00, 28.30s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 457.671875 319.7467155456543 True\n",
            "Prompt executed in 847.10 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed nud...\n",
            "Token info: CLIP tokens: 120/182\n",
            "Kept 120/182 tokens (65.9%)\n",
            "Dropped content: \"in</w> a</w> secret</w> garden</w> with</w>...\"\n",
            "\u001b[33m[rgthree-comfy][Power Prompt]\u001b[00m Lora \"FLUX1_Anatomy_really_sagging_breasts.safetensors\" not found, skipping.\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Nipples.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 3 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            " 18% 5/28 [04:57<22:46, 59.43s/it][ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            " 61% 17/28 [17:49<11:32, 62.92s/it]\n",
            "Processing interrupted\n",
            "Prompt executed in 1125.92 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed nude ((watercolor painting:1.2) by Serg...\n",
            "Token info: CLIP tokens: 120/137\n",
            "Kept 120/137 tokens (87.6%)\n",
            "Dropped content: \"peaceful</w> and</w> serene</w> .</w> her</w>...\"\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            " 25% 7/28 [06:50<20:30, 58.59s/it]FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            " 29% 8/28 [07:49<19:31, 58.59s/it]\n",
            "  0% 0.00/11.3M [00:00<?, ?B/s]\u001b[A\n",
            " 45% 5.08M/11.3M [00:00<00:00, 31.5MB/s]\u001b[A\n",
            "100% 11.3M/11.3M [00:00<00:00, 30.1MB/s]\n",
            "Extracted zip file to /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-diffusers\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', \n",
            "'diffusers>=0.29.0']\n",
            "                                         \n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', \n",
            "'accelerate']\n",
            "                                    [ComfyUI-Manager] skip black listed pip installation: 'transformers'\n",
            "[ComfyUI-Manager] skip black listed pip installation: 'safetensors'\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', \n",
            "'omegaconf']\n",
            "   \n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', \n",
            "'pytorch_lightning']\n",
            "                                        \n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', \n",
            "'xformers']\n",
            "                         \n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', \n",
            "'git+https://github.com/cumulo-autumn/StreamDiffusion.git@main#egg=streamdiffusi\n",
            "on']\n",
            "[!] DEPRECATION: git+https://github.com/cumulo-autumn/StreamDiffusion.git@main#egg=streamdiffusion[tensorrt] contains an egg fragment with a non-PEP 508 name. pip 25.1 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/13157\n",
            " Collecting streamdiffusion (from streamdiffusion[tensorrt])\n",
            "   Cloning https://github.com/cumulo-autumn/StreamDiffusion.git (to revision main) to /tmp/pip-install-tcb3_1id/streamdiffusion_be3a2edafe7949d4b7658d3ed8cfa0e1\n",
            "[!]   Running command git clone --filter=blob:none --quiet https://github.com/cumulo-autumn/StreamDiffusion.git /tmp/pip-install-tcb3_1id/streamdiffusion_be3a2edafe7949d4b7658d3ed8cfa0e1\n",
            "   Resolved https://github.com/cumulo-autumn/StreamDiffusion.git to commit b623251dc055e1fd858d53509aa43e09dfc5cdc0\n",
            "   Installing build dependencies: started\n",
            "   Installing build dependencies: finished with status 'done'\n",
            "   Getting requirements to build wheel: started\n",
            "   Getting requirements to build wheel: finished with status 'done'\n",
            "   Preparing metadata (pyproject.toml): started\n",
            "   Preparing metadata (pyproject.toml): finished with status 'done'\n",
            " Collecting fire (from streamdiffusion->streamdiffusion[tensorrt])\n",
            "   Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "   Preparing metadata (setup.py): started\n",
            "   Preparing metadata (setup.py): finished with status 'done'\n",
            "  Collecting diffusers==0.24.0 (from streamdiffusion->streamdiffusion[tensorrt])\n",
            "   Downloading diffusers-0.24.0-py3-none-any.whl.metadata (18 kB)\n",
            "           Collecting protobuf==3.20.2 (from streamdiffusion->streamdiffusion[tensorrt])\n",
            "   Downloading protobuf-3.20.2-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "  Collecting onnx==1.15.0 (from streamdiffusion->streamdiffusion[tensorrt])\n",
            "   Downloading onnx-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            " Collecting onnxruntime==1.16.3 (from streamdiffusion->streamdiffusion[tensorrt])\n",
            "   Downloading onnxruntime-1.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
            " Collecting colored (from streamdiffusion->streamdiffusion[tensorrt])\n",
            "   Downloading colored-2.3.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "                                      Downloading diffusers-0.24.0-py3-none-any.whl (1.8 MB)\n",
            "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.8/1.8 MB 77.6 MB/s eta 0:00:00\n",
            " Downloading onnx-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 15.7/15.7 MB 108.3 MB/s eta 0:00:00\n",
            " Downloading onnxruntime-1.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.4/6.4 MB 118.2 MB/s eta 0:00:00\n",
            " Downloading protobuf-3.20.2-py2.py3-none-any.whl (162 kB)\n",
            " Downloading colored-2.3.0-py3-none-any.whl (18 kB)\n",
            " Building wheels for collected packages: streamdiffusion, fire\n",
            "   Building wheel for streamdiffusion (pyproject.toml): started\n",
            "   Building wheel for streamdiffusion (pyproject.toml): finished with status 'done'\n",
            "   Created wheel for streamdiffusion: filename=streamdiffusion-0.1.1-py3-none-any.whl size=29759 sha256=6454cadd09800ca02fa398241f22c9a293d9fb831d6e52880bb6da3d9d8ac2a5\n",
            "   Stored in directory: /tmp/pip-ephem-wheel-cache-trt4er4s/wheels/95/59/ee/f181b26036fe5ae1d3ac2640a709b11115004eb8dce7100f51\n",
            "   Building wheel for fire (setup.py): started\n",
            "   Building wheel for fire (setup.py): finished with status 'done'\n",
            "   Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114332 sha256=a58d06b084136bf6e1ccf9eba035c5f2265d7b294db463d176100426f01a576b\n",
            "   Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            " Successfully built streamdiffusion fire\n",
            " 32% 9/28 [08:47<18:32, 58.57s/it] Installing collected packages: protobuf, fire, colored, onnxruntime, onnx, diffusers, streamdiffusion\n",
            "   Attempting uninstall: protobuf\n",
            "     Found existing installation: protobuf 5.29.4\n",
            "     Uninstalling protobuf-5.29.4:\n",
            "       Successfully uninstalled protobuf-5.29.4\n",
            "   Attempting uninstall: onnxruntime\n",
            "     Found existing installation: onnxruntime 1.21.1\n",
            "     Uninstalling onnxruntime-1.21.1:\n",
            "       Successfully uninstalled onnxruntime-1.21.1\n",
            "   Attempting uninstall: diffusers\n",
            "     Found existing installation: diffusers 0.32.2\n",
            "     Uninstalling diffusers-0.32.2:\n",
            "       Successfully uninstalled diffusers-0.32.2\n",
            " Successfully installed colored-2.3.0 diffusers-0.24.0 fire-0.7.0 onnx-1.15.0 onnxruntime-1.16.3 protobuf-3.20.2 streamdiffusion-0.1.1\n",
            "[!] ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "[!] tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.2 which is incompatible.\n",
            "[!] tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n",
            "[!] grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.2 which is incompatible.\n",
            "[!] ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.2 which is incompatible.\n",
            "\n",
            "[ComfyUI-Manager] Queued works are completed.\n",
            "{'install': 1}\n",
            "\n",
            "After restarting ComfyUI, please refresh the browser.\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            " 57% 16/28 [15:37<11:41, 58.49s/it]FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "[ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            " 64% 18/28 [17:34<09:44, 58.42s/it]\n",
            "  0% 0.00/101k [00:00<?, ?B/s]\u001b[A\n",
            " 65% 65.5k/101k [00:00<00:00, 298kB/s]\u001b[A\n",
            "100% 101k/101k [00:00<00:00, 266kB/s] \n",
            "Extracted zip file to /content/drive/MyDrive/ComfyUI/custom_nodes/comfyui-videohelpersuite\n",
            "Install: pip packages\n",
            "\n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', \n",
            "'opencv-python']\n",
            "  \n",
            "## ComfyUI-Manager: EXECUTE => ['/usr/bin/python3', '-m', 'pip', 'install', \n",
            "'imageio-ffmpeg']\n",
            " \n",
            "[ComfyUI-Manager] Queued works are completed.\n",
            "{'install': 1}\n",
            "\n",
            "After restarting ComfyUI, please refresh the browser.\n",
            "100% 28/28 [27:18<00:00, 58.52s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1700.62 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: \n",
            "Token info: CLIP tokens: 0\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 8486.0 8485.68359375 0\n",
            "100% 28/28 [20:42<00:00, 44.37s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1304.44 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed nud...\n",
            "Token info: CLIP tokens: 120/142\n",
            "Kept 120/142 tokens (84.5%)\n",
            "Dropped content: \"she</w> is</w> bold</w> .</w> the</w>...\"\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            "100% 28/28 [27:33<00:00, 59.06s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1736.14 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: lostplace <lora:lost_Places_bf16:.2>A Detailed Pho...\n",
            "Token info: CLIP tokens: 36\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"lost_Places_bf16.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 9050.48 9047.228637695312 226\n",
            "100% 28/28 [18:47<00:00, 40.26s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1183.69 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed nude (Photograph:1.2) by SergeMarsh <lo...\n",
            "Token info: CLIP tokens: 120/140\n",
            "Kept 120/140 tokens (85.7%)\n",
            "Dropped content: \"shy</w> and</w> withdrawn</w> .</w> the</w>...\"\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Hairy_Art-000001.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            "100% 28/28 [27:32<00:00, 59.01s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "0 models unloaded.\n",
            "loaded partially 128.0 127.99951171875 0\n",
            "Prompt executed in 1733.59 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed (Photograph:1.2) by SergeMarsh <lora:UN...\n",
            "Token info: CLIP tokens: 119\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"Nipples.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 2 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "Requested to load Flux\n",
            "loaded partially 11781.488000000001 11781.48779296875 196\n",
            "100% 28/28 [07:46<00:00, 16.67s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "loaded completely 384.23046875 319.7467155456543 True\n",
            "Prompt executed in 532.45 seconds\n",
            "\n",
            "HTDynamicPromptNode v1.4.0 - Processing\n",
            "Generated prompt: A Detailed (Photograph:1.2) by SergeMarsh <lora:UN...\n",
            "Token info: CLIP tokens: 120\n",
            "\u001b[92m[rgthree-comfy][Power Prompt]\u001b[00m Loaded \"UNKNOWN/SergeMarshFlux.safetensors\" from prompt\u001b[00m\n",
            "\u001b[36m[rgthree-comfy][Power Prompt]\u001b[00m 1 Loras processed; stripping tags for TEXT output.\u001b[00m\n",
            "Requested to load FluxClipModel_\n",
            "loaded completely 9.5367431640625e+25 9319.23095703125 True\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1742899825_extension-node-map.json [DONE]\n",
            "Requested to load Flux\n",
            "loaded partially 7276.400000000001 7276.291015625 243\n",
            "  0% 0/28 [00:00<?, ?it/s][ComfyUI-Manager] The ComfyRegistry cache update is still in progress, so an outdated cache is being used.\n",
            "nightly_channel: \n",
            "https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/cache\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/1514988643_custom-node-list.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/746607195_github-stats.json [DONE]\n",
            "FETCH DATA from: /content/drive/MyDrive/ComfyUI/user/default/ComfyUI-Manager/cache/832903789_extras.json [DONE]\n",
            " 25% 7/28 [06:50<20:32, 58.68s/it]"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}